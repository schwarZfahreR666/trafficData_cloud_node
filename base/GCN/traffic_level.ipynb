{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f819f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "from py2neo import Graph,Node,NodeMatcher\n",
    "import pandas as pd\n",
    "import dgl.function as fn\n",
    "import numpy as np\n",
    "from __future__ import division, print_function\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "import shelve\n",
    "from base.GCN.GraphSAGE import GCN,Classifier,Model\n",
    "from base.GCN.XGboost import XGBoost\n",
    "graph = Graph(\"http://47.95.159.86/:7474\",auth=(\"neo4j\",\"06240118\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8289ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取国家体育馆4跳之内的路名节点\n",
    "query = \"match (p:gym {name:'国家体育馆'})-[edge*1..4]->(q:road) return id(q) as qid,q.name as name;\"\n",
    "res = graph.run(query).data()\n",
    "nodesid = set()\n",
    "name2id = {}\n",
    "id2name = {}\n",
    "for row in res:\n",
    "    nodesid.add(row['qid'])\n",
    "    name2id[row['name']] = row['qid']\n",
    "    id2name[row['qid']] = row['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8997f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到各个路段\n",
    "query = \"match (p:road)-->(q:road) where id(q) in \" + str(list(nodesid)) + \" and id(p) in \" + str(list(nodesid)) + \" return id(p) as pid,id(q) as qid;\"\n",
    "res = graph.run(query).data()\n",
    "road_starts = []\n",
    "road_ends = []\n",
    "for row in res:\n",
    "    road_starts.append(row['pid'])\n",
    "    road_ends.append(row['qid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b8be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到与gym直接相连的路段\n",
    "query = \"match (p:gym)-->(q:road) where id(p)=0 return id(p) as pid,id(q) as qid;\"\n",
    "res = graph.run(query).data()\n",
    "gym_starts = []\n",
    "gym_ends = []\n",
    "for row in res:\n",
    "    gym_starts.append(row['pid'])\n",
    "    gym_ends.append(row['qid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e4810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到路段默认等级、限速\n",
    "level2speed = {\"1\":100,\"2\":100,\"3\":80,\"4\":80,\"5\":60,\"6\":60}\n",
    "query = \"match (p:road) where id(p) in \" + str(list(nodesid)) + \" return id(p) as pid,p.road_level as level;\"\n",
    "res = graph.run(query).data()\n",
    "id2level = {}\n",
    "for row in res:\n",
    "    id2level[row['pid']] = row['level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e600b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建gym和road两类节点的异质图\n",
    "graph_data = {\n",
    "   ('road', 'direct', 'gym'): (torch.tensor(gym_ends),torch.tensor(gym_starts)),\n",
    "   ('road', 'link', 'road'): (torch.tensor(road_starts), torch.tensor(road_ends))\n",
    "}\n",
    "g = dgl.heterograph(graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据组成\n",
    "data_file = \"./data.json\"\n",
    "data = []\n",
    "label = []\n",
    "with open(data_file,'r') as fd:\n",
    "        content = json.load(fd)\n",
    "        for item in content:\n",
    "            dic = {}\n",
    "            for key in item.keys():\n",
    "                if key in name2id:\n",
    "                    dic[name2id[key]] = item[key]\n",
    "                if key == 'label':\n",
    "                    label.append(item[key])\n",
    "            data.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f49301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按id顺序组装数据\n",
    "x_data = []  # data_num * node_num\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "ITEM_LEN = 6\n",
    "for item in data:\n",
    "    data_item = []\n",
    "    for i in range(NODE_NUM):\n",
    "        if i in item:\n",
    "            if i in id2level:\n",
    "                new_item = [x if x != -1 else level2speed[id2level[i]] for x in item[i]]\n",
    "            else:\n",
    "                new_item = [60 for x in item[i]]\n",
    "            data_item.append(new_item)\n",
    "        else:\n",
    "            if i in id2level:\n",
    "                default_item = [level2speed[id2level[i]] for _ in range(ITEM_LEN)]\n",
    "            else:\n",
    "                default_item = [60 for _ in range(ITEM_LEN)]\n",
    "            data_item.append(default_item)\n",
    "    x_data.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10508373",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.FloatTensor(x_data)\n",
    "_train_labels = [1,2,3]\n",
    "onehot_encoded = list()\n",
    "for value in label:\n",
    "    letter = [0 for _ in range(len(_train_labels))]\n",
    "    letter[value-1] = 1\n",
    "    onehot_encoded.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa6bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462 220 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_data.shape[0]):\n",
    "    g.nodes['road'].data['speed'] = input_data[i]\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('speed', 'm'), fn.mean('m', 'h_1'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('h_1', 'm'), fn.mean('m', 'h_2'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('h_2', 'm'), fn.mean('m', 'h_3'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['direct'] = (fn.copy_u('h_3', 'f'), fn.mean('f', 'level'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    level = torch.sum(g.nodes['gym'].data['level'] - 70)\n",
    "    traffic_level = 1\n",
    "    if float(level) < 13:\n",
    "        traffic_level = 2\n",
    "    if float(level) < 12:\n",
    "        traffic_level = 3\n",
    "    label[i] = traffic_level\n",
    "print(label.count(1),label.count(2),label.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbb915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for v in label:\n",
    "    item = []\n",
    "    item.append(v-1)\n",
    "    res.append(item)\n",
    "train_label = torch.LongTensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c6d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(12, 12)\n",
    "#         self.fc2 = nn.Linear(12, 6)\n",
    "#         self.sc1 = nn.Linear(12, 6)\n",
    "#         self.bn1 = nn.BatchNorm1d(12)\n",
    "#         self.ac1 = nn.LeakyReLU()\n",
    "\n",
    "#         self.fc3 = nn.Linear(12, 12)\n",
    "#         self.fc4 = nn.Linear(12, 6)\n",
    "#         self.sc2 = nn.Linear(12, 6)\n",
    "#         self.bn2 = nn.BatchNorm1d(12)\n",
    "#         self.ac2 = nn.LeakyReLU()\n",
    "        \n",
    "#         self.fc5 = nn.Linear(12, 12)\n",
    "#         self.fc6 = nn.Linear(12, 6)\n",
    "#         self.sc3 = nn.Linear(12, 6)\n",
    "#         self.bn3 = nn.BatchNorm1d(12)\n",
    "#         self.ac3 = nn.LeakyReLU()\n",
    "#     def forward(self, g, h):\n",
    "#         g.nodes['road'].data['speed'] = h\n",
    "        \n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('speed', 'm'), fn.mean('m', 'h_1'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h1_ = g.ndata['h_1']['road']\n",
    "        \n",
    "#         h1 = self.fc1(torch.cat([h, h1_], dim=1))\n",
    "#         x = h1\n",
    "#         h1 = self.bn1(h1)\n",
    "#         h1 = self.ac1(h1)\n",
    "#         h1 = self.fc2(h1) + self.sc1(x)\n",
    "        \n",
    "        \n",
    "#         g.nodes['road'].data['h_1'] = h1\n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('h_1', 'm'), fn.mean('m', 'h_2'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h2_ = g.ndata['h_2']['road']\n",
    "        \n",
    "#         h2 = self.fc3(torch.cat([h1, h2_], dim=1))\n",
    "#         x = h2\n",
    "#         h2 = self.bn2(h2)\n",
    "#         h2 = self.ac2(h2)\n",
    "#         h2 = self.fc4(h2) + self.sc2(x)\n",
    "        \n",
    "#         g.nodes['road'].data['h_2'] = h2\n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('h_2', 'm'), fn.mean('m', 'h_3'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h3_ = g.ndata['h_3']['road']\n",
    "        \n",
    "#         h3 = self.fc5(torch.cat([h2, h3_], dim=1))\n",
    "#         x = h3\n",
    "#         h3 = self.bn3(h3)\n",
    "#         h3 = self.ac3(h3)\n",
    "#         h3 = self.fc6(h3) + self.sc3(x)\n",
    "        \n",
    "#         g.nodes['road'].data['h_3'] = h3\n",
    "#         funcs = {}\n",
    "#         funcs['direct'] = (fn.copy_u('h_3', 'f'), fn.mean('f', 'level'))\n",
    "#         g.multi_update_all(funcs, 'sum')\n",
    "        \n",
    "#         return g.nodes['gym'].data['level']\n",
    "    \n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.classifier = nn.Linear(6, 3)\n",
    "#     def forward(self,h):\n",
    "#         res = self.classifier(h)\n",
    "#         return res\n",
    "    \n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self,gcn,classifier):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.gcn = gcn\n",
    "#         self.classifier = classifier\n",
    "#     def forward(self,g,h):\n",
    "#         res = self.classifier(self.gcn(g,h))\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01361c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,g, model,input_data,input_label):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "    p_num = 0\n",
    "    t_num = 0\n",
    "    pre_acc = 0\n",
    "    for ep in range(epoch):\n",
    "        for e in range(input_data.shape[0]):\n",
    "            # Forward\n",
    "            logits = model(g, input_data[e])\n",
    "\n",
    "            # Compute prediction\n",
    "            pred = logits.argmax(1)\n",
    "\n",
    "            # Compute loss\n",
    "            # Note that we should only compute the losses of the nodes in the training set,\n",
    "            # i.e. with train_mask 1.\n",
    "            loss = F.cross_entropy(logits, input_label[e])\n",
    "\n",
    "            # Compute accuracy on training/validation/test\n",
    "            train_acc = (pred == train_label[e]).float().mean()\n",
    "            p_num += (pred == train_label[e]).float()\n",
    "            t_num += 1\n",
    "\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc = float(p_num / t_num * 100)\n",
    "        print('acc: {:.3f}%'.format(acc))\n",
    "    torch.save(model.state_dict(), './model/GraphSAGE_pram.pkl')\n",
    "    print(\"better model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN()\n",
    "classifier = Classifier()\n",
    "model = Model(gcn,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd55a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 67.344%\n",
      "acc: 72.424%\n",
      "acc: 69.473%\n",
      "acc: 67.671%\n",
      "acc: 66.589%\n",
      "acc: 66.304%\n",
      "acc: 66.038%\n",
      "acc: 65.729%\n",
      "acc: 66.280%\n",
      "acc: 66.183%\n",
      "acc: 66.117%\n",
      "acc: 65.989%\n",
      "acc: 66.071%\n",
      "acc: 65.986%\n",
      "acc: 65.893%\n",
      "acc: 65.620%\n",
      "acc: 65.440%\n",
      "acc: 65.602%\n",
      "acc: 65.396%\n",
      "acc: 65.174%\n",
      "acc: 65.747%\n",
      "acc: 65.662%\n",
      "acc: 65.615%\n",
      "acc: 65.469%\n",
      "acc: 65.393%\n",
      "acc: 65.239%\n",
      "acc: 65.237%\n",
      "acc: 65.131%\n",
      "acc: 65.052%\n",
      "acc: 64.998%\n",
      "acc: 65.190%\n",
      "acc: 65.208%\n",
      "acc: 65.171%\n",
      "acc: 65.500%\n",
      "acc: 65.354%\n",
      "acc: 65.393%\n",
      "acc: 65.469%\n",
      "acc: 65.465%\n",
      "acc: 65.364%\n",
      "acc: 65.370%\n",
      "acc: 65.372%\n",
      "acc: 65.305%\n",
      "acc: 65.356%\n",
      "acc: 65.540%\n",
      "acc: 65.506%\n",
      "acc: 65.498%\n",
      "acc: 65.436%\n",
      "acc: 65.418%\n",
      "acc: 65.386%\n",
      "acc: 65.405%\n",
      "acc: 65.528%\n",
      "acc: 65.600%\n",
      "acc: 65.619%\n",
      "acc: 65.629%\n",
      "acc: 65.645%\n",
      "acc: 65.584%\n",
      "acc: 65.549%\n",
      "acc: 65.505%\n",
      "acc: 65.499%\n",
      "acc: 65.416%\n",
      "acc: 65.388%\n",
      "acc: 65.385%\n",
      "acc: 65.379%\n",
      "acc: 65.507%\n",
      "acc: 65.538%\n",
      "acc: 65.651%\n",
      "acc: 65.776%\n",
      "acc: 65.829%\n",
      "acc: 65.853%\n",
      "acc: 65.884%\n",
      "acc: 65.839%\n",
      "acc: 65.800%\n",
      "acc: 65.759%\n",
      "acc: 65.832%\n",
      "acc: 65.811%\n",
      "acc: 65.770%\n",
      "acc: 65.861%\n",
      "acc: 65.800%\n",
      "acc: 65.777%\n",
      "acc: 65.787%\n",
      "acc: 65.907%\n",
      "acc: 65.978%\n",
      "acc: 66.060%\n",
      "acc: 66.126%\n",
      "acc: 66.229%\n",
      "acc: 66.320%\n",
      "acc: 66.411%\n",
      "acc: 66.481%\n",
      "acc: 66.556%\n",
      "acc: 66.633%\n",
      "acc: 66.709%\n",
      "acc: 66.793%\n",
      "acc: 66.851%\n",
      "acc: 66.899%\n",
      "acc: 66.947%\n",
      "acc: 66.948%\n",
      "acc: 66.949%\n",
      "acc: 67.046%\n",
      "acc: 67.039%\n",
      "acc: 67.026%\n",
      "better model is saved\n"
     ]
    }
   ],
   "source": [
    "train(100,g,model,input_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae7bccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.769532233476639\n",
      "-7.8545286655426025\n",
      "-7.832947313785553\n",
      "-7.800883859395981\n",
      "-7.790611028671265\n",
      "-7.793244004249573\n",
      "-7.818482607603073\n",
      "-7.838344186544418\n",
      "-7.875929981470108\n",
      "-7.868527680635452\n",
      "-7.862983614206314\n",
      "-7.866086393594742\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.849625051021576\n",
      "-7.829213082790375\n",
      "-7.889557600021362\n",
      "-7.838497459888458\n",
      "-7.879251480102539\n",
      "-7.882717281579971\n",
      "-7.850777834653854\n",
      "-7.912915229797363\n",
      "-7.865494638681412\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.785492449998856\n",
      "-7.789125204086304\n",
      "-7.792875200510025\n",
      "-7.785986661911011\n",
      "-7.842447102069855\n",
      "-7.879643529653549\n",
      "-7.871657699346542\n",
      "-7.808419167995453\n",
      "-7.79306373000145\n",
      "-7.8910729587078094\n",
      "-7.835995674133301\n",
      "-7.797374576330185\n",
      "-7.800874799489975\n",
      "-7.861610144376755\n",
      "-7.922272771596909\n",
      "-7.792319178581238\n",
      "-7.767986446619034\n",
      "-7.817034482955933\n",
      "-7.823686569929123\n",
      "-7.826103061437607\n",
      "-7.796884715557098\n",
      "-7.847454458475113\n",
      "-7.779459536075592\n",
      "-7.758839100599289\n",
      "-7.804060161113739\n",
      "-7.8017018139362335\n",
      "-7.815820425748825\n",
      "-7.773303925991058\n",
      "-7.772007524967194\n",
      "-7.776774346828461\n",
      "-7.772241324186325\n",
      "-7.773864030838013\n",
      "-7.837468922138214\n",
      "-7.8729009330272675\n",
      "-7.866574287414551\n",
      "-7.862652957439423\n",
      "-7.866145938634872\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.763460457324982\n",
      "-7.768643915653229\n",
      "-7.775556147098541\n",
      "-7.838861495256424\n",
      "-7.772169202566147\n",
      "-7.756173104047775\n",
      "-7.785238593816757\n",
      "-7.797996252775192\n",
      "-7.895373970270157\n",
      "-7.777380675077438\n",
      "-7.756124347448349\n",
      "-7.793872654438019\n",
      "-7.789125889539719\n",
      "-7.81496998667717\n",
      "-7.774703621864319\n",
      "-7.782665729522705\n",
      "-7.7890050411224365\n",
      "-7.775875627994537\n",
      "-7.7731781005859375\n",
      "-7.774616718292236\n",
      "-7.780769973993301\n",
      "-7.779003798961639\n",
      "-7.7825852036476135\n",
      "-7.778690040111542\n",
      "-7.777032345533371\n",
      "-7.775191217660904\n",
      "-7.777967214584351\n",
      "-7.776290267705917\n",
      "-7.838926523923874\n",
      "-7.759596347808838\n",
      "-7.752582371234894\n",
      "-7.781186938285828\n",
      "-7.845649540424347\n",
      "-7.922553181648254\n",
      "-7.7937526404857635\n",
      "-7.817994922399521\n",
      "-7.880757451057434\n",
      "-7.881310909986496\n",
      "-7.912883669137955\n",
      "-7.865933328866959\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.782062739133835\n",
      "-7.782257974147797\n",
      "-7.784313201904297\n",
      "-7.78014275431633\n",
      "-7.778745114803314\n",
      "-7.840400576591492\n",
      "-7.763642400503159\n",
      "-7.7606140077114105\n",
      "-7.789996087551117\n",
      "-7.784726142883301\n",
      "-7.820684641599655\n",
      "-7.778779596090317\n",
      "-7.780556172132492\n",
      "-7.7751719653606415\n",
      "-7.777087718248367\n",
      "-7.783367067575455\n",
      "-7.777010530233383\n",
      "-7.7798469960689545\n",
      "-7.779123306274414\n",
      "-7.7821750938892365\n",
      "-7.779523730278015\n",
      "-7.7773628532886505\n",
      "-7.777830481529236\n",
      "-7.776898622512817\n",
      "-7.777752995491028\n",
      "-7.776758313179016\n",
      "-7.840091675519943\n",
      "-7.874512851238251\n",
      "-7.867332577705383\n",
      "-7.802588939666748\n",
      "-7.79191666841507\n",
      "-7.837806850671768\n",
      "-7.8943478763103485\n",
      "-7.921387851238251\n",
      "-7.805745631456375\n",
      "-7.836545348167419\n",
      "-7.881150126457214\n",
      "-7.884764730930328\n",
      "-7.912491202354431\n",
      "-7.870012551546097\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.867504000663757\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.841775894165039\n",
      "-7.87794554233551\n",
      "-7.9076754450798035\n",
      "-7.881028026342392\n",
      "-7.912906169891357\n",
      "-7.865620285272598\n",
      "-7.902949333190918\n",
      "-7.848363071680069\n",
      "-7.826847434043884\n",
      "-7.8340513706207275\n",
      "-7.822525203227997\n",
      "-7.815316557884216\n",
      "-7.776460021734238\n",
      "-7.772449731826782\n",
      "-7.770684152841568\n",
      "-7.768292635679245\n",
      "-7.773712605237961\n",
      "-7.77974197268486\n",
      "-7.780345141887665\n",
      "-7.7769856452941895\n",
      "-7.781100958585739\n",
      "-7.784827321767807\n",
      "-7.786503911018372\n",
      "-7.845665544271469\n",
      "-7.783229738473892\n",
      "-7.77139937877655\n",
      "-7.8482517302036285\n",
      "-7.87001371383667\n",
      "-7.949296146631241\n",
      "-7.7659807205200195\n",
      "-7.8476035594940186\n",
      "-7.927583575248718\n",
      "-7.7773639261722565\n",
      "-7.7792772352695465\n",
      "-7.7757569551467896\n",
      "-7.838368982076645\n",
      "-7.872468173503876\n",
      "-7.79644587635994\n",
      "-7.762877970933914\n",
      "-7.8508957624435425\n",
      "-7.841423153877258\n",
      "-7.8031986951828\n",
      "-7.783368527889252\n",
      "-7.796573787927628\n",
      "-7.8215959668159485\n",
      "-7.777865678071976\n",
      "-7.775011271238327\n",
      "-7.7753497660160065\n",
      "-7.778629124164581\n",
      "-7.776038944721222\n",
      "-7.775864869356155\n",
      "-7.78153058886528\n",
      "-7.785605579614639\n",
      "-7.789627254009247\n",
      "-7.788348376750946\n",
      "-7.782971173524857\n",
      "-7.787299424409866\n",
      "-7.782267540693283\n",
      "-7.84869909286499\n",
      "-7.764015227556229\n",
      "-7.7579821944236755\n",
      "-7.785069316625595\n",
      "-7.77927365899086\n",
      "-7.888904392719269\n",
      "-7.873400241136551\n",
      "-7.86624202132225\n",
      "-7.8602718114852905\n",
      "-7.862157106399536\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.863471537828445\n",
      "-7.862389922142029\n",
      "-7.896146506071091\n",
      "-7.948338717222214\n",
      "-7.806259900331497\n",
      "-7.788396000862122\n",
      "-7.8520717322826385\n",
      "-7.917050838470459\n",
      "-7.896592795848846\n",
      "-7.780758112668991\n",
      "-7.79059761762619\n",
      "-7.852215796709061\n",
      "-7.9140938222408295\n",
      "-7.80930569767952\n",
      "-7.8331159055233\n",
      "-7.800395041704178\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.845101058483124\n",
      "-7.879652321338654\n",
      "-7.907243520021439\n",
      "-7.829177141189575\n",
      "-7.810429751873016\n",
      "-7.850827664136887\n",
      "-7.898367375135422\n",
      "-7.921950101852417\n",
      "-7.862003922462463\n",
      "-7.865620285272598\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.813972294330597\n",
      "-7.837109953165054\n",
      "-7.835221379995346\n",
      "-7.782660961151123\n",
      "-7.776975303888321\n",
      "-7.785774856805801\n",
      "-7.847895532846451\n",
      "-7.882562905550003\n",
      "-7.8667913377285\n",
      "-7.864784926176071\n",
      "-7.806630551815033\n",
      "-7.818580001592636\n",
      "-7.833126246929169\n",
      "-7.826929271221161\n",
      "-7.8174534142017365\n",
      "-7.837381601333618\n",
      "-7.871996164321899\n",
      "-7.867438197135925\n",
      "-7.862661510705948\n",
      "-7.865482121706009\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.783548712730408\n",
      "-7.782224088907242\n",
      "-7.782322555780411\n",
      "-7.784726023674011\n",
      "-7.785200893878937\n",
      "-7.78650763630867\n",
      "-7.787968218326569\n",
      "-7.8486308157444\n",
      "-7.772653728723526\n",
      "-7.771180897951126\n",
      "-7.8046450316905975\n",
      "-7.79427769780159\n",
      "-7.816266775131226\n",
      "-7.788926959037781\n",
      "-7.797025918960571\n",
      "-7.778933763504028\n",
      "-7.776256799697876\n",
      "-7.782669812440872\n",
      "-7.7885675728321075\n",
      "-7.782738566398621\n",
      "-7.7802733182907104\n",
      "-7.782856613397598\n",
      "-7.782142817974091\n",
      "-7.782605051994324\n",
      "-7.7822438180446625\n",
      "-7.776382625102997\n",
      "-7.84052449464798\n",
      "-7.876741468906403\n",
      "-7.792263388633728\n",
      "-7.758092969655991\n",
      "-7.8039020001888275\n",
      "-7.888147473335266\n",
      "-7.922686368227005\n",
      "-7.865286141633987\n",
      "-7.858571767807007\n",
      "-7.863167881965637\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.842930793762207\n",
      "-7.87854191660881\n",
      "-7.907526403665543\n",
      "-7.881590932607651\n",
      "-7.912854999303818\n",
      "-7.866259187459946\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.779188364744186\n",
      "-7.7842691242694855\n",
      "-7.784624695777893\n",
      "-7.779505699872971\n",
      "-7.775557965040207\n",
      "-7.776684403419495\n",
      "-7.778492599725723\n",
      "-7.78298345208168\n",
      "-7.779858738183975\n",
      "-7.777466416358948\n",
      "-7.783554494380951\n",
      "-7.777655452489853\n",
      "-7.7786634266376495\n",
      "-7.781836628913879\n",
      "-7.78374382853508\n",
      "-7.7908075749874115\n",
      "-7.7821827828884125\n",
      "-7.780756235122681\n",
      "-7.779573947191238\n",
      "-7.781309902667999\n",
      "-7.784090667963028\n",
      "-7.78560534119606\n",
      "-7.774435788393021\n",
      "-7.766916751861572\n",
      "-7.7716273963451385\n",
      "-7.772756457328796\n",
      "-7.7744626104831696\n",
      "-7.768845647573471\n",
      "-7.835767954587936\n",
      "-7.870599418878555\n",
      "-7.865473091602325\n",
      "-7.8601618111133575\n",
      "-7.86635822057724\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.783045470714569\n",
      "-7.779654324054718\n",
      "-7.766324579715729\n",
      "-7.770984530448914\n",
      "-7.776030451059341\n",
      "-7.7779808938503265\n",
      "-7.768395513296127\n",
      "-7.834431290626526\n",
      "-7.874230712652206\n",
      "-7.867548853158951\n",
      "-7.802470564842224\n",
      "-7.838334321975708\n",
      "-7.906744748353958\n",
      "-7.884318560361862\n",
      "-7.912554055452347\n",
      "-7.869465529918671\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.850039333105087\n",
      "-7.8257118463516235\n",
      "-7.832029044628143\n",
      "-7.889910101890564\n",
      "-7.83519634604454\n",
      "-7.830091029405594\n",
      "-7.87804189324379\n",
      "-7.8476570546627045\n",
      "-7.839560776948929\n",
      "-7.836445599794388\n",
      "-7.907809197902679\n",
      "-7.881222426891327\n",
      "-7.912948846817017\n",
      "-7.865012377500534\n",
      "-7.902949333190918\n",
      "-7.857115060091019\n",
      "-7.885544955730438\n",
      "-7.906962752342224\n",
      "-7.888133078813553\n",
      "-7.911908894777298\n",
      "-7.874291330575943\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.805257946252823\n",
      "-7.81510117650032\n",
      "-7.82617712020874\n",
      "-7.798870712518692\n",
      "-7.8187636733055115\n",
      "-7.773711204528809\n",
      "-7.785608559846878\n",
      "-7.797224968671799\n",
      "-7.848746687173843\n",
      "-7.869773298501968\n",
      "-7.78626349568367\n",
      "-7.772888243198395\n",
      "-7.855168431997299\n",
      "-7.8446433544158936\n",
      "-7.817613631486893\n",
      "-7.802033871412277\n",
      "-7.854437559843063\n",
      "-7.840719252824783\n",
      "-7.768919676542282\n",
      "-7.802718013525009\n",
      "-7.798864334821701\n",
      "-7.816182434558868\n",
      "-7.77451229095459\n",
      "-7.780681073665619\n",
      "-7.771780461072922\n",
      "-7.835352033376694\n",
      "-7.759298264980316\n",
      "-7.770143747329712\n",
      "-7.796504735946655\n",
      "-7.842155575752258\n",
      "-7.838253319263458\n",
      "-7.764107674360275\n",
      "-7.801442891359329\n",
      "-7.787242740392685\n",
      "-7.892360031604767\n",
      "-7.764660984277725\n",
      "-7.8299039006233215\n",
      "-7.87724494934082\n",
      "-7.8476722240448\n",
      "-7.912839710712433\n",
      "-7.812520742416382\n",
      "-7.880527347326279\n",
      "-7.907009482383728\n",
      "-7.883457541465759\n",
      "-7.912662029266357\n",
      "-7.868427366018295\n",
      "-7.842942714691162\n",
      "-7.878551572561264\n",
      "-7.9075294733047485\n",
      "-7.881596058607101\n",
      "-7.912856638431549\n",
      "-7.866264671087265\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.834232598543167\n",
      "-7.816248029470444\n",
      "-7.838658720254898\n",
      "-7.892019331455231\n",
      "-7.8432416915893555\n",
      "-7.749491095542908\n",
      "-7.840678930282593\n",
      "-7.870060622692108\n",
      "-7.922167778015137\n",
      "-7.862411946058273\n",
      "-7.7932144701480865\n",
      "-7.857117146253586\n",
      "-7.919783592224121\n",
      "-7.87231382727623\n",
      "-7.862739771604538\n",
      "-7.865929007530212\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.839949816465378\n",
      "-7.876992076635361\n",
      "-7.907897740602493\n",
      "-7.825805246829987\n",
      "-7.820914596319199\n",
      "-7.81282964348793\n",
      "-7.8225317895412445\n",
      "-7.819142669439316\n",
      "-7.777082473039627\n",
      "-7.781150221824646\n",
      "-7.838227778673172\n",
      "-7.8730661273002625\n",
      "-7.868642449378967\n",
      "-7.86198553442955\n",
      "-7.8080703020095825\n",
      "-7.879151672124863\n",
      "-7.907372623682022\n",
      "-7.882168024778366\n",
      "-7.912798166275024\n",
      "-7.866923958063126\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.849575102329254\n",
      "-7.781497687101364\n",
      "-7.793598532676697\n",
      "-7.781278133392334\n",
      "-7.784780651330948\n",
      "-7.778445243835449\n",
      "-7.783631443977356\n",
      "-7.796963542699814\n",
      "-7.782916814088821\n",
      "-7.774369329214096\n",
      "-7.776651442050934\n",
      "-7.785692453384399\n",
      "-7.7826191782951355\n",
      "-7.768987208604813\n",
      "-7.77122238278389\n",
      "-7.77484330534935\n",
      "-7.776104241609573\n",
      "-7.779121547937393\n",
      "-7.77464696764946\n",
      "-7.773391455411911\n",
      "-7.776463896036148\n",
      "-7.780146509408951\n",
      "-7.784728556871414\n",
      "-7.781281620264053\n",
      "-7.782675802707672\n",
      "-7.78285077214241\n",
      "-7.78566038608551\n",
      "-7.7818396389484406\n",
      "-7.77842590212822\n",
      "-7.842576414346695\n",
      "-7.752485007047653\n",
      "-7.751841872930527\n",
      "-7.840426713228226\n",
      "-7.861225187778473\n",
      "-7.9235213696956635\n",
      "-7.85768535733223\n",
      "-7.862847000360489\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.782385468482971\n",
      "-7.787156462669373\n",
      "-7.793012738227844\n",
      "-7.847764700651169\n",
      "-7.876795381307602\n",
      "-7.794033378362656\n",
      "-7.773518472909927\n",
      "-7.826005965471268\n",
      "-7.894469052553177\n",
      "-7.841320693492889\n",
      "-7.82324481010437\n",
      "-7.878466784954071\n",
      "-7.854394346475601\n",
      "-7.9128555953502655\n",
      "-7.813082367181778\n",
      "-7.830725342035294\n",
      "-7.890345901250839\n",
      "-7.901924401521683\n",
      "-7.919151395559311\n"
     ]
    }
   ],
   "source": [
    "mid_data = []\n",
    "for x in range(input_data.shape[0]):\n",
    "    logits = model(g, input_data[x])\n",
    "    pred = logits.argmax(1)\n",
    "#     print(pred,label[x])\n",
    "    level = gcn(g, input_data[x])\n",
    "    mid_data.append(level[0].tolist())\n",
    "for lis in mid_data:\n",
    "    print(sum(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d822ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.769532233476639\n",
      "-7.8545286655426025\n",
      "-7.832947313785553\n",
      "-7.800883859395981\n",
      "-7.790611028671265\n",
      "-7.793244004249573\n",
      "-7.818482607603073\n",
      "-7.838344186544418\n",
      "-7.875929981470108\n",
      "-7.868527680635452\n",
      "-7.862983614206314\n",
      "-7.866086393594742\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.849625051021576\n",
      "-7.829213082790375\n",
      "-7.889557600021362\n",
      "-7.838497459888458\n",
      "-7.879251480102539\n",
      "-7.882717281579971\n",
      "-7.850777834653854\n",
      "-7.912915229797363\n",
      "-7.865494638681412\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.785492449998856\n",
      "-7.789125204086304\n",
      "-7.792875200510025\n",
      "-7.785986661911011\n",
      "-7.842447102069855\n",
      "-7.879643529653549\n",
      "-7.871657699346542\n",
      "-7.808419167995453\n",
      "-7.79306373000145\n",
      "-7.8910729587078094\n",
      "-7.835995674133301\n",
      "-7.797374576330185\n",
      "-7.800874799489975\n",
      "-7.861610144376755\n",
      "-7.922272771596909\n",
      "-7.792319178581238\n",
      "-7.767986446619034\n",
      "-7.817034482955933\n",
      "-7.823686569929123\n",
      "-7.826103061437607\n",
      "-7.796884715557098\n",
      "-7.847454458475113\n",
      "-7.779459536075592\n",
      "-7.758839100599289\n",
      "-7.804060161113739\n",
      "-7.8017018139362335\n",
      "-7.815820425748825\n",
      "-7.773303925991058\n",
      "-7.772007524967194\n",
      "-7.776774346828461\n",
      "-7.772241324186325\n",
      "-7.773864030838013\n",
      "-7.837468922138214\n",
      "-7.8729009330272675\n",
      "-7.866574287414551\n",
      "-7.862652957439423\n",
      "-7.866145938634872\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.763460457324982\n",
      "-7.768643915653229\n",
      "-7.775556147098541\n",
      "-7.838861495256424\n",
      "-7.772169202566147\n",
      "-7.756173104047775\n",
      "-7.785238593816757\n",
      "-7.797996252775192\n",
      "-7.895373970270157\n",
      "-7.777380675077438\n",
      "-7.756124347448349\n",
      "-7.793872654438019\n",
      "-7.789125889539719\n",
      "-7.81496998667717\n",
      "-7.774703621864319\n",
      "-7.782665729522705\n",
      "-7.7890050411224365\n",
      "-7.775875627994537\n",
      "-7.7731781005859375\n",
      "-7.774616718292236\n",
      "-7.780769973993301\n",
      "-7.779003798961639\n",
      "-7.7825852036476135\n",
      "-7.778690040111542\n",
      "-7.777032345533371\n",
      "-7.775191217660904\n",
      "-7.777967214584351\n",
      "-7.776290267705917\n",
      "-7.838926523923874\n",
      "-7.759596347808838\n",
      "-7.752582371234894\n",
      "-7.781186938285828\n",
      "-7.845649540424347\n",
      "-7.922553181648254\n",
      "-7.7937526404857635\n",
      "-7.817994922399521\n",
      "-7.880757451057434\n",
      "-7.881310909986496\n",
      "-7.912883669137955\n",
      "-7.865933328866959\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.782062739133835\n",
      "-7.782257974147797\n",
      "-7.784313201904297\n",
      "-7.78014275431633\n",
      "-7.778745114803314\n",
      "-7.840400576591492\n",
      "-7.763642400503159\n",
      "-7.7606140077114105\n",
      "-7.789996087551117\n",
      "-7.784726142883301\n",
      "-7.820684641599655\n",
      "-7.778779596090317\n",
      "-7.780556172132492\n",
      "-7.7751719653606415\n",
      "-7.777087718248367\n",
      "-7.783367067575455\n",
      "-7.777010530233383\n",
      "-7.7798469960689545\n",
      "-7.779123306274414\n",
      "-7.7821750938892365\n",
      "-7.779523730278015\n",
      "-7.7773628532886505\n",
      "-7.777830481529236\n",
      "-7.776898622512817\n",
      "-7.777752995491028\n",
      "-7.776758313179016\n",
      "-7.840091675519943\n",
      "-7.874512851238251\n",
      "-7.867332577705383\n",
      "-7.802588939666748\n",
      "-7.79191666841507\n",
      "-7.837806850671768\n",
      "-7.8943478763103485\n",
      "-7.921387851238251\n",
      "-7.805745631456375\n",
      "-7.836545348167419\n",
      "-7.881150126457214\n",
      "-7.884764730930328\n",
      "-7.912491202354431\n",
      "-7.870012551546097\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.867504000663757\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.841775894165039\n",
      "-7.87794554233551\n",
      "-7.9076754450798035\n",
      "-7.881028026342392\n",
      "-7.912906169891357\n",
      "-7.865620285272598\n",
      "-7.902949333190918\n",
      "-7.848363071680069\n",
      "-7.826847434043884\n",
      "-7.8340513706207275\n",
      "-7.822525203227997\n",
      "-7.815316557884216\n",
      "-7.776460021734238\n",
      "-7.772449731826782\n",
      "-7.770684152841568\n",
      "-7.768292635679245\n",
      "-7.773712605237961\n",
      "-7.77974197268486\n",
      "-7.780345141887665\n",
      "-7.7769856452941895\n",
      "-7.781100958585739\n",
      "-7.784827321767807\n",
      "-7.786503911018372\n",
      "-7.845665544271469\n",
      "-7.783229738473892\n",
      "-7.77139937877655\n",
      "-7.8482517302036285\n",
      "-7.87001371383667\n",
      "-7.949296146631241\n",
      "-7.7659807205200195\n",
      "-7.8476035594940186\n",
      "-7.927583575248718\n",
      "-7.7773639261722565\n",
      "-7.7792772352695465\n",
      "-7.7757569551467896\n",
      "-7.838368982076645\n",
      "-7.872468173503876\n",
      "-7.79644587635994\n",
      "-7.762877970933914\n",
      "-7.8508957624435425\n",
      "-7.841423153877258\n",
      "-7.8031986951828\n",
      "-7.783368527889252\n",
      "-7.796573787927628\n",
      "-7.8215959668159485\n",
      "-7.777865678071976\n",
      "-7.775011271238327\n",
      "-7.7753497660160065\n",
      "-7.778629124164581\n",
      "-7.776038944721222\n",
      "-7.775864869356155\n",
      "-7.78153058886528\n",
      "-7.785605579614639\n",
      "-7.789627254009247\n",
      "-7.788348376750946\n",
      "-7.782971173524857\n",
      "-7.787299424409866\n",
      "-7.782267540693283\n",
      "-7.84869909286499\n",
      "-7.764015227556229\n",
      "-7.7579821944236755\n",
      "-7.785069316625595\n",
      "-7.77927365899086\n",
      "-7.888904392719269\n",
      "-7.873400241136551\n",
      "-7.86624202132225\n",
      "-7.8602718114852905\n",
      "-7.862157106399536\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.863471537828445\n",
      "-7.862389922142029\n",
      "-7.896146506071091\n",
      "-7.948338717222214\n",
      "-7.806259900331497\n",
      "-7.788396000862122\n",
      "-7.8520717322826385\n",
      "-7.917050838470459\n",
      "-7.896592795848846\n",
      "-7.780758112668991\n",
      "-7.79059761762619\n",
      "-7.852215796709061\n",
      "-7.9140938222408295\n",
      "-7.80930569767952\n",
      "-7.8331159055233\n",
      "-7.800395041704178\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.845101058483124\n",
      "-7.879652321338654\n",
      "-7.907243520021439\n",
      "-7.829177141189575\n",
      "-7.810429751873016\n",
      "-7.850827664136887\n",
      "-7.898367375135422\n",
      "-7.921950101852417\n",
      "-7.862003922462463\n",
      "-7.865620285272598\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.813972294330597\n",
      "-7.837109953165054\n",
      "-7.835221379995346\n",
      "-7.782660961151123\n",
      "-7.776975303888321\n",
      "-7.785774856805801\n",
      "-7.847895532846451\n",
      "-7.882562905550003\n",
      "-7.8667913377285\n",
      "-7.864784926176071\n",
      "-7.806630551815033\n",
      "-7.818580001592636\n",
      "-7.833126246929169\n",
      "-7.826929271221161\n",
      "-7.8174534142017365\n",
      "-7.837381601333618\n",
      "-7.871996164321899\n",
      "-7.867438197135925\n",
      "-7.862661510705948\n",
      "-7.865482121706009\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.783548712730408\n",
      "-7.782224088907242\n",
      "-7.782322555780411\n",
      "-7.784726023674011\n",
      "-7.785200893878937\n",
      "-7.78650763630867\n",
      "-7.787968218326569\n",
      "-7.8486308157444\n",
      "-7.772653728723526\n",
      "-7.771180897951126\n",
      "-7.8046450316905975\n",
      "-7.79427769780159\n",
      "-7.816266775131226\n",
      "-7.788926959037781\n",
      "-7.797025918960571\n",
      "-7.778933763504028\n",
      "-7.776256799697876\n",
      "-7.782669812440872\n",
      "-7.7885675728321075\n",
      "-7.782738566398621\n",
      "-7.7802733182907104\n",
      "-7.782856613397598\n",
      "-7.782142817974091\n",
      "-7.782605051994324\n",
      "-7.7822438180446625\n",
      "-7.776382625102997\n",
      "-7.84052449464798\n",
      "-7.876741468906403\n",
      "-7.792263388633728\n",
      "-7.758092969655991\n",
      "-7.8039020001888275\n",
      "-7.888147473335266\n",
      "-7.922686368227005\n",
      "-7.865286141633987\n",
      "-7.858571767807007\n",
      "-7.863167881965637\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.842930793762207\n",
      "-7.87854191660881\n",
      "-7.907526403665543\n",
      "-7.881590932607651\n",
      "-7.912854999303818\n",
      "-7.866259187459946\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.779188364744186\n",
      "-7.7842691242694855\n",
      "-7.784624695777893\n",
      "-7.779505699872971\n",
      "-7.775557965040207\n",
      "-7.776684403419495\n",
      "-7.778492599725723\n",
      "-7.78298345208168\n",
      "-7.779858738183975\n",
      "-7.777466416358948\n",
      "-7.783554494380951\n",
      "-7.777655452489853\n",
      "-7.7786634266376495\n",
      "-7.781836628913879\n",
      "-7.78374382853508\n",
      "-7.7908075749874115\n",
      "-7.7821827828884125\n",
      "-7.780756235122681\n",
      "-7.779573947191238\n",
      "-7.781309902667999\n",
      "-7.784090667963028\n",
      "-7.78560534119606\n",
      "-7.774435788393021\n",
      "-7.766916751861572\n",
      "-7.7716273963451385\n",
      "-7.772756457328796\n",
      "-7.7744626104831696\n",
      "-7.768845647573471\n",
      "-7.835767954587936\n",
      "-7.870599418878555\n",
      "-7.865473091602325\n",
      "-7.8601618111133575\n",
      "-7.86635822057724\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.783045470714569\n",
      "-7.779654324054718\n",
      "-7.766324579715729\n",
      "-7.770984530448914\n",
      "-7.776030451059341\n",
      "-7.7779808938503265\n",
      "-7.768395513296127\n",
      "-7.834431290626526\n",
      "-7.874230712652206\n",
      "-7.867548853158951\n",
      "-7.802470564842224\n",
      "-7.838334321975708\n",
      "-7.906744748353958\n",
      "-7.884318560361862\n",
      "-7.912554055452347\n",
      "-7.869465529918671\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.850039333105087\n",
      "-7.8257118463516235\n",
      "-7.832029044628143\n",
      "-7.889910101890564\n",
      "-7.83519634604454\n",
      "-7.830091029405594\n",
      "-7.87804189324379\n",
      "-7.8476570546627045\n",
      "-7.839560776948929\n",
      "-7.836445599794388\n",
      "-7.907809197902679\n",
      "-7.881222426891327\n",
      "-7.912948846817017\n",
      "-7.865012377500534\n",
      "-7.902949333190918\n",
      "-7.857115060091019\n",
      "-7.885544955730438\n",
      "-7.906962752342224\n",
      "-7.888133078813553\n",
      "-7.911908894777298\n",
      "-7.874291330575943\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.805257946252823\n",
      "-7.81510117650032\n",
      "-7.82617712020874\n",
      "-7.798870712518692\n",
      "-7.8187636733055115\n",
      "-7.773711204528809\n",
      "-7.785608559846878\n",
      "-7.797224968671799\n",
      "-7.848746687173843\n",
      "-7.869773298501968\n",
      "-7.78626349568367\n",
      "-7.772888243198395\n",
      "-7.855168431997299\n",
      "-7.8446433544158936\n",
      "-7.817613631486893\n",
      "-7.802033871412277\n",
      "-7.854437559843063\n",
      "-7.840719252824783\n",
      "-7.768919676542282\n",
      "-7.802718013525009\n",
      "-7.798864334821701\n",
      "-7.816182434558868\n",
      "-7.77451229095459\n",
      "-7.780681073665619\n",
      "-7.771780461072922\n",
      "-7.835352033376694\n",
      "-7.759298264980316\n",
      "-7.770143747329712\n",
      "-7.796504735946655\n",
      "-7.842155575752258\n",
      "-7.838253319263458\n",
      "-7.764107674360275\n",
      "-7.801442891359329\n",
      "-7.787242740392685\n",
      "-7.892360031604767\n",
      "-7.764660984277725\n",
      "-7.8299039006233215\n",
      "-7.87724494934082\n",
      "-7.8476722240448\n",
      "-7.912839710712433\n",
      "-7.812520742416382\n",
      "-7.880527347326279\n",
      "-7.907009482383728\n",
      "-7.883457541465759\n",
      "-7.912662029266357\n",
      "-7.868427366018295\n",
      "-7.842942714691162\n",
      "-7.878551572561264\n",
      "-7.9075294733047485\n",
      "-7.881596058607101\n",
      "-7.912856638431549\n",
      "-7.866264671087265\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.834232598543167\n",
      "-7.816248029470444\n",
      "-7.838658720254898\n",
      "-7.892019331455231\n",
      "-7.8432416915893555\n",
      "-7.749491095542908\n",
      "-7.840678930282593\n",
      "-7.870060622692108\n",
      "-7.922167778015137\n",
      "-7.862411946058273\n",
      "-7.7932144701480865\n",
      "-7.857117146253586\n",
      "-7.919783592224121\n",
      "-7.87231382727623\n",
      "-7.862739771604538\n",
      "-7.865929007530212\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.839949816465378\n",
      "-7.876992076635361\n",
      "-7.907897740602493\n",
      "-7.825805246829987\n",
      "-7.820914596319199\n",
      "-7.81282964348793\n",
      "-7.8225317895412445\n",
      "-7.819142669439316\n",
      "-7.777082473039627\n",
      "-7.781150221824646\n",
      "-7.838227778673172\n",
      "-7.8730661273002625\n",
      "-7.868642449378967\n",
      "-7.86198553442955\n",
      "-7.8080703020095825\n",
      "-7.879151672124863\n",
      "-7.907372623682022\n",
      "-7.882168024778366\n",
      "-7.912798166275024\n",
      "-7.866923958063126\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.849575102329254\n",
      "-7.781497687101364\n",
      "-7.793598532676697\n",
      "-7.781278133392334\n",
      "-7.784780651330948\n",
      "-7.778445243835449\n",
      "-7.783631443977356\n",
      "-7.796963542699814\n",
      "-7.782916814088821\n",
      "-7.774369329214096\n",
      "-7.776651442050934\n",
      "-7.785692453384399\n",
      "-7.7826191782951355\n",
      "-7.768987208604813\n",
      "-7.77122238278389\n",
      "-7.77484330534935\n",
      "-7.776104241609573\n",
      "-7.779121547937393\n",
      "-7.77464696764946\n",
      "-7.773391455411911\n",
      "-7.776463896036148\n",
      "-7.780146509408951\n",
      "-7.784728556871414\n",
      "-7.781281620264053\n",
      "-7.782675802707672\n",
      "-7.78285077214241\n",
      "-7.78566038608551\n",
      "-7.7818396389484406\n",
      "-7.77842590212822\n",
      "-7.842576414346695\n",
      "-7.752485007047653\n",
      "-7.751841872930527\n",
      "-7.840426713228226\n",
      "-7.861225187778473\n",
      "-7.9235213696956635\n",
      "-7.85768535733223\n",
      "-7.862847000360489\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.902949333190918\n",
      "-7.782385468482971\n",
      "-7.787156462669373\n",
      "-7.793012738227844\n",
      "-7.847764700651169\n",
      "-7.876795381307602\n",
      "-7.794033378362656\n",
      "-7.773518472909927\n",
      "-7.826005965471268\n",
      "-7.894469052553177\n",
      "-7.841320693492889\n",
      "-7.82324481010437\n",
      "-7.878466784954071\n",
      "-7.854394346475601\n",
      "-7.9128555953502655\n",
      "-7.813082367181778\n",
      "-7.830725342035294\n",
      "-7.890345901250839\n",
      "-7.901924401521683\n",
      "-7.919151395559311\n"
     ]
    }
   ],
   "source": [
    "# load_model = torch.load(\"./model/GraphSAGE.pkl\")\n",
    "gcn = GCN()\n",
    "classifier = Classifier()\n",
    "load_model = Model(gcn,classifier)\n",
    "load_model.load_state_dict(torch.load(\"./model/GraphSAGE_pram.pkl\"))\n",
    "# load_model.eval()\n",
    "for x in range(input_data.shape[0]):\n",
    "    level = load_model.gcn(g, input_data[x])\n",
    "    print(sum(level[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a5d8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_widgets = [\n",
    "#     'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
    "#     ' ', progressbar.ETA()\n",
    "# ]\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n",
    "    mse = np.mean(np.power(y_true - y_pred, 2))\n",
    "    return mse\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    \n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    # Split the training data from test data in the ratio specified in\n",
    "    # test_size\n",
    "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "    X_train, X_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# def divide_on_feature(X, feature_i, threshold):\n",
    "#     \"\"\" Divide dataset based on if sample value on feature index is larger than\n",
    "#         the given threshold \"\"\"\n",
    "#     split_func = None\n",
    "#     if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "#         split_func = lambda sample: sample[feature_i] >= threshold\n",
    "#     else:\n",
    "#         split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "#     X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "#     X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
    "\n",
    "#     return np.array([X_1, X_2])\n",
    "\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]\n",
    "def pred2label(old):\n",
    "    new = []\n",
    "    for v in old:\n",
    "        new.append(round(v[0]))\n",
    "    return np.array(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3ca9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecisionNode():\n",
    "#     \"\"\"Class that represents a decision node or leaf in the decision tree\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     feature_i: int\n",
    "#         Feature index which we want to use as the threshold measure.\n",
    "#     threshold: float\n",
    "#         The value that we will compare feature values at feature_i against to\n",
    "#         determine the prediction.\n",
    "#     value: float\n",
    "#         The class prediction if classification tree, or float value if regression tree.\n",
    "#     true_branch: DecisionNode\n",
    "#         Next decision node for samples where features value met the threshold.\n",
    "#     false_branch: DecisionNode\n",
    "#         Next decision node for samples where features value did not meet the threshold.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, feature_i=None, threshold=None,\n",
    "#                  value=None, true_branch=None, false_branch=None):\n",
    "#         self.feature_i = feature_i  # Index for the feature that is tested\n",
    "#         self.threshold = threshold  # Threshold value for feature\n",
    "#         self.value = value  # Value if the node is a leaf in the tree\n",
    "#         self.true_branch = true_branch  # 'Left' subtree\n",
    "#         self.false_branch = false_branch  # 'Right' subtree\n",
    "        \n",
    "# class DecisionTree(object):\n",
    "#     \"\"\"Super class of RegressionTree and ClassificationTree.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     min_samples_split: int\n",
    "#         The minimum number of samples needed to make a split when building a tree.\n",
    "#     min_impurity: float\n",
    "#         The minimum impurity required to split the tree further.\n",
    "#     max_depth: int\n",
    "#         The maximum depth of a tree.\n",
    "#     loss: function\n",
    "#         Loss function that is used for Gradient Boosting models to calculate impurity.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, min_samples_split=2, min_impurity=1e-7,\n",
    "#                  max_depth=float(\"inf\"), loss=None):\n",
    "#         self.root = None  # Root node in dec. tree\n",
    "#         # Minimum n of samples to justify split\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#         # The minimum impurity to justify split\n",
    "#         self.min_impurity = min_impurity\n",
    "#         # The maximum depth to grow the tree to\n",
    "#         self.max_depth = max_depth\n",
    "#         # Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)\n",
    "#         # 切割树的方法，gini，方差等\n",
    "#         self._impurity_calculation = None\n",
    "#         # Function to determine prediction of y at leaf\n",
    "#         # 树节点取值的方法，分类树：选取出现最多次数的值，回归树：取所有值的平均值\n",
    "#         self._leaf_value_calculation = None\n",
    "#         # If y is one-hot encoded (multi-dim) or not (one-dim)\n",
    "#         self.one_dim = None\n",
    "#         # If Gradient Boost\n",
    "#         self.loss = loss\n",
    "\n",
    "#     def fit(self, X, y, loss=None):\n",
    "#         \"\"\" Build decision tree \"\"\"\n",
    "#         self.one_dim = len(np.shape(y)) == 1\n",
    "#         self.root = self._build_tree(X, y)\n",
    "#         self.loss = None\n",
    "\n",
    "#     def _build_tree(self, X, y, current_depth=0):\n",
    "#         \"\"\" Recursive method which builds out the decision tree and splits X and respective y\n",
    "#         on the feature of X which (based on impurity) best separates the data\"\"\"\n",
    "#         largest_impurity = 0\n",
    "#         best_criteria = None  # Feature index and threshold\n",
    "#         best_sets = None  # Subsets of the data\n",
    "\n",
    "#         # Check if expansion of y is needed  [1,2,3,4,5] -> [[1],[2],[3],[4],[5]]\n",
    "#         if len(np.shape(y)) == 1:\n",
    "#             y = np.expand_dims(y, axis=1)\n",
    "\n",
    "#         # Add y as last column of X\n",
    "#         Xy = np.concatenate((X, y), axis=1)\n",
    "\n",
    "#         n_samples, n_features = np.shape(X)\n",
    "#         # 节点样本数大于节点阈值并且没有达到最大树深\n",
    "#         if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "#             # Calculate the impurity for each feature\n",
    "#             for feature_i in range(n_features):\n",
    "#                 # All values of feature_i\n",
    "#                 feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "#                 unique_values = np.unique(feature_values)\n",
    "\n",
    "#                 # Iterate through all unique values of feature column i and\n",
    "#                 # calculate the impurity\n",
    "#                 for threshold in unique_values:\n",
    "#                     # Divide X and y depending on if the feature value of X at index feature_i\n",
    "#                     # meets the threshold\n",
    "#                     # 根据分割值分割样本\n",
    "#                     Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
    "\n",
    "#                     if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "#                         # Select the y-values of the two sets\n",
    "#                         # 拿到两部分的label\n",
    "#                         y1 = Xy1[:, n_features:]\n",
    "#                         y2 = Xy2[:, n_features:]\n",
    "\n",
    "#                         # Calculate impurity\n",
    "#                         impurity = self._impurity_calculation(y, y1, y2)\n",
    "\n",
    "#                         # If this threshold resulted in a higher information gain than previously\n",
    "#                         # recorded save the threshold value and the feature\n",
    "#                         # index\n",
    "#                         if impurity > largest_impurity:\n",
    "#                             largest_impurity = impurity\n",
    "#                             best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
    "#                             best_sets = {\n",
    "#                                 \"leftX\": Xy1[:, :n_features],  # X of left subtree\n",
    "#                                 \"lefty\": Xy1[:, n_features:],  # y of left subtree\n",
    "#                                 \"rightX\": Xy2[:, :n_features],  # X of right subtree\n",
    "#                                 \"righty\": Xy2[:, n_features:]  # y of right subtree\n",
    "#                             }\n",
    "\n",
    "#         if largest_impurity > self.min_impurity:\n",
    "#             # Build subtrees for the right and left branches\n",
    "#             true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
    "#             false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
    "#             return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\n",
    "#                 \"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "#         # We're at leaf => determine value\n",
    "#         leaf_value = self._leaf_value_calculation(y)\n",
    "#         return DecisionNode(value=leaf_value)\n",
    "\n",
    "#     def predict_value(self, x, tree=None):\n",
    "#         \"\"\" Do a recursive search down the tree and make a prediction of the data sample by the\n",
    "#             value of the leaf that we end up at \"\"\"\n",
    "\n",
    "#         if tree is None:\n",
    "#             tree = self.root\n",
    "\n",
    "#         # If we have a value (i.e we're at a leaf) => return value as the prediction\n",
    "#         if tree.value is not None:\n",
    "#             return tree.value\n",
    "\n",
    "#         # Choose the feature that we will test\n",
    "#         feature_value = x[tree.feature_i]\n",
    "\n",
    "#         # Determine if we will follow left or right branch\n",
    "#         branch = tree.false_branch\n",
    "#         if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "#             if feature_value >= tree.threshold:\n",
    "#                 branch = tree.true_branch\n",
    "#         elif feature_value == tree.threshold:\n",
    "#             branch = tree.true_branch\n",
    "\n",
    "#         # Test subtree\n",
    "#         return self.predict_value(x, branch)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\" Classify samples one by one and return the set of labels \"\"\"\n",
    "#         y_pred = []\n",
    "#         for x in X:\n",
    "#             y_pred.append(self.predict_value(x))\n",
    "#         return y_pred\n",
    "\n",
    "#     def print_tree(self, tree=None, indent=\" \"):\n",
    "#         \"\"\" Recursively print the decision tree \"\"\"\n",
    "#         if not tree:\n",
    "#             tree = self.root\n",
    "\n",
    "#         # If we're at leaf => print the label\n",
    "#         if tree.value is not None:\n",
    "#             print(tree.value)\n",
    "#         # Go deeper down the tree\n",
    "#         else:\n",
    "#             # Print test\n",
    "#             print(\"%s:%s? \" % (tree.feature_i, tree.threshold))\n",
    "#             # Print the true scenario\n",
    "#             print(\"%sT->\" % (indent), end=\"\")\n",
    "#             self.print_tree(tree.true_branch, indent + indent)\n",
    "#             # Print the false scenario\n",
    "#             print(\"%sF->\" % (indent), end=\"\")\n",
    "#             self.print_tree(tree.false_branch, indent + indent)\n",
    "\n",
    "# class LeastSquaresLoss():\n",
    "#     \"\"\"Least squares loss\"\"\"\n",
    "\n",
    "#     # g是loss一阶导\n",
    "#     def gradient(self, actual, predicted):\n",
    "#         return actual - predicted\n",
    "\n",
    "#     # h是loss二阶导\n",
    "#     def hess(self, actual, predicted):\n",
    "#         return np.ones_like(actual)\n",
    "\n",
    "# class XGBoostRegressionTree(DecisionTree):\n",
    "#     \"\"\"\n",
    "#     Regression tree for XGBoost\n",
    "#     - Reference -\n",
    "#     http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _split(self, y):\n",
    "#         \"\"\" y contains y_true in left half of the middle column and\n",
    "#         y_pred in the right half. Split and return the two matrices \"\"\"\n",
    "#         col = int(np.shape(y)[1]/2)\n",
    "#         y, y_pred = y[:, :col], y[:, col:]\n",
    "#         return y, y_pred\n",
    "\n",
    "#     def _gain(self, y, y_pred):\n",
    "#         nominator = np.power((self.loss.gradient(y, y_pred)).sum(), 2)\n",
    "#         denominator = self.loss.hess(y, y_pred).sum()\n",
    "#         return 0.5 * (nominator / denominator)\n",
    "\n",
    "#     def _gain_by_taylor(self, y, y1, y2):\n",
    "#         # Split\n",
    "#         y, y_pred = self._split(y)\n",
    "#         y1, y1_pred = self._split(y1)\n",
    "#         y2, y2_pred = self._split(y2)\n",
    "\n",
    "#         true_gain = self._gain(y1, y1_pred)\n",
    "#         false_gain = self._gain(y2, y2_pred)\n",
    "#         gain = self._gain(y, y_pred)\n",
    "#         return true_gain + false_gain - gain\n",
    "\n",
    "#     def _approximate_update(self, y):\n",
    "#         # y split into y, y_pred\n",
    "#         y, y_pred = self._split(y)\n",
    "#         gradient = np.sum(self.loss.gradient(y, y_pred),axis=0)\n",
    "#         hessian = np.sum(self.loss.hess(y, y_pred), axis=0)\n",
    "#         update_approximation =  gradient / hessian\n",
    "#         return update_approximation\n",
    "\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self._impurity_calculation = self._gain_by_taylor\n",
    "#         self._leaf_value_calculation = self._approximate_update\n",
    "#         super(XGBoostRegressionTree, self).fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class XGBoost(object):\n",
    "#     \"\"\"The XGBoost classifier.\n",
    "\n",
    "#     Reference: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     n_estimators: int\n",
    "#         The number of classification trees that are used.\n",
    "#     learning_rate: float\n",
    "#         The step length that will be taken when following the negative gradient during\n",
    "#         training.\n",
    "#     min_samples_split: int\n",
    "#         The minimum number of samples needed to make a split when building a tree.\n",
    "#     min_impurity: float\n",
    "#         The minimum impurity required to split the tree further.\n",
    "#     max_depth: int\n",
    "#         The maximum depth of a tree.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, n_estimators=200, learning_rate=0.01, min_samples_split=2,\n",
    "#                  min_impurity=1e-7, max_depth=2):\n",
    "#         self.n_estimators = n_estimators  # Number of trees\n",
    "#         self.learning_rate = learning_rate  # Step size for weight update\n",
    "#         self.min_samples_split = min_samples_split  # The minimum n of sampels to justify split\n",
    "#         self.min_impurity = min_impurity  # Minimum variance reduction to continue\n",
    "#         self.max_depth = max_depth  # Maximum depth for tree\n",
    "\n",
    "#         self.bar = progressbar.ProgressBar(widgets=bar_widgets)\n",
    "\n",
    "#         # Log loss for classification\n",
    "#         self.loss = LeastSquaresLoss()\n",
    "\n",
    "#         # Initialize regression trees\n",
    "#         self.trees = []\n",
    "#         for _ in range(n_estimators):\n",
    "#             tree = XGBoostRegressionTree(\n",
    "#                 min_samples_split=self.min_samples_split,\n",
    "#                 min_impurity=min_impurity,\n",
    "#                 max_depth=self.max_depth,\n",
    "#                 loss=self.loss)\n",
    "\n",
    "#             self.trees.append(tree)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         # y = to_categorical(y)\n",
    "#         m = X.shape[0]\n",
    "#         y = np.reshape(y, (m, -1))\n",
    "#         y_pred = np.zeros(np.shape(y))\n",
    "#         for i in self.bar(range(self.n_estimators)):\n",
    "#             tree = self.trees[i]\n",
    "#             y_and_pred = np.concatenate((y, y_pred), axis=1)\n",
    "#             tree.fit(X, y_and_pred)\n",
    "#             update_pred = tree.predict(X)\n",
    "#             update_pred = np.reshape(update_pred, (m, -1))\n",
    "#             y_pred += update_pred\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         y_pred = None\n",
    "#         m = X.shape[0]\n",
    "#         # Make predictions\n",
    "#         for tree in self.trees:\n",
    "#             # Estimate gradient and update prediction\n",
    "#             update_pred = tree.predict(X)\n",
    "#             update_pred = np.reshape(update_pred, (m, -1))\n",
    "#             if y_pred is None:\n",
    "#                 y_pred = np.zeros_like(update_pred)\n",
    "#             y_pred += update_pred\n",
    "\n",
    "#         return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b419f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print (\"-- XGBoost --\")\n",
    "    mid_data = np.array(mid_data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mid_data, label, test_size=0.5)\n",
    "    print(y_train)\n",
    "#     model = XGBoost()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     y_pred_line = model.predict(X)\n",
    "#     print(y_test[0:5])\n",
    "#     # Color map\n",
    "#     cmap = plt.get_cmap('viridis')\n",
    "\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "#     print (\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445c846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% [                                               ] ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- XGBoost --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangran/Desktop/traffic_platform/base/GCN/DecisionTree.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array([X_1, X_2])\n",
      "Training: 100% [------------------------------------------------] Time: 0:10:55\r\n"
     ]
    }
   ],
   "source": [
    "print (\"-- XGBoost --\")\n",
    "xg_data = np.array(mid_data)\n",
    "xg_label = np.array(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xg_data, xg_label, test_size=0.1)\n",
    "xg_model = XGBoost()\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bd34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error:0.481,acc:1.000\n",
      "Test Mean Squared Error:0.581,acc:0.971\n"
     ]
    }
   ],
   "source": [
    "y_tra = xg_model.predict(X_train)\n",
    "\n",
    "y_pred = xg_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_tra)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "acc_train = accuracy_score(y_train, pred2label(y_tra))\n",
    "acc_test = accuracy_score(y_test, pred2label(y_pred))\n",
    "\n",
    "\n",
    "print (\"Train Mean Squared Error:{:.3f},acc:{:.3f}\".format(float(mse_train),float(acc_train)))\n",
    "print (\"Test Mean Squared Error:{:.3f},acc:{:.3f}\".format(float(mse_test),float(acc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ed1de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 3 1 1 1 1 2 1 1 2 2 2 1\n",
      " 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 2 2 1 3]\n",
      "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg_model.predict(X_test)\n",
    "print(y_test)\n",
    "y_pd = []\n",
    "for v in y_pred:\n",
    "    y_pd.append(round(v[0]))\n",
    "print(y_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330bf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入\n",
    "def save(model):                      \n",
    "    db = shelve.open('./model/xg_boost')       # 创建二进制文件  赋值句柄给db\n",
    "    db['model'] = model         # 把实例化后的对象s赋值给db key为s\n",
    "    db.close()          # 保险起见  关闭一下文件 shelve自带的方法  .close()\n",
    "\n",
    "\n",
    "# 读取\n",
    "def read_shelve():\n",
    "    db = shelve.open('./model/xg_boost')           # 打开文件  赋值句柄给db\n",
    "    model = db['model']        # 把db['s']的值取出来给st\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97e4a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(xg_model.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.GCN.LevelAnalysisModel import ATAnalysisModel\n",
    "from base.GCN.XGBoostTree import XGBoostRegressionTree\n",
    "from base.GCN.DecisionTree import DecisionTree\n",
    "from base.GCN.DecisionNode import DecisionNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1dae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = ATAnalysisModel()\n",
    "predict_model.buildGraph(graph)\n",
    "ans = []\n",
    "for x in range(input_data.shape[0]):\n",
    "    res = predict_model.predict(input_data[x])\n",
    "    ans.append(res)\n",
    "xg_label = np.array(label)\n",
    "print(accuracy_score(np.array(label),np.array(ans)))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model.build_data()\n",
    "for item in predict_model.input_data[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {'京藏高速':22.1}\n",
    "predict_model.update_data(data_dic)\n",
    "for item in predict_model.input_data[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据组成\n",
    "data_file = \"./at_default_data.json\"\n",
    "data = []\n",
    "with open(data_file,'r') as fd:\n",
    "        content = json.load(fd)\n",
    "        dic = {}\n",
    "        for item in content:\n",
    "            \n",
    "            if item in name2id:\n",
    "                dic[name2id[item]] = content[item]\n",
    "        data.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按id顺序组装数据\n",
    "x_data = []  # data_num * node_num\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "ITEM_LEN = 6\n",
    "for item in data:\n",
    "    print(item)\n",
    "    data_item = []\n",
    "    for i in range(NODE_NUM):\n",
    "        if i in item:\n",
    "            if i in id2level:\n",
    "                new_item = [x if x != -1 else level2speed[id2level[i]] for x in item[i]]\n",
    "            else:\n",
    "                new_item = [60 for x in item[i]]\n",
    "            data_item.append(new_item)\n",
    "        else:\n",
    "            if i in id2level:\n",
    "                default_item = [level2speed[id2level[i]] for _ in range(ITEM_LEN)]\n",
    "            else:\n",
    "                default_item = [60 for _ in range(ITEM_LEN)]\n",
    "            data_item.append(default_item)\n",
    "    x_data.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e5308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.FloatTensor(x_data)\n",
    "data_np = input_data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eeb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1,2,3,4,5])\n",
    "num = -1\n",
    "fill_value = 0\n",
    "\n",
    "def shift(arr, num, fill_value):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:][:num] = fill_value\n",
    "        result[:][num:] = arr[:][:-num]\n",
    "    elif num < 0:\n",
    "        result[:][num:] = fill_value\n",
    "        result[:][:num] = arr[:][-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    print(result)\n",
    "shift(array, num, fill_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f249d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_np[:,:,1:data_np.shape[2]].shape)\n",
    "print(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {'京藏高速':22.1}\n",
    "np_array = input_data.numpy()\n",
    "old = np_array[:,:,:np_array.shape[2] - 1]\n",
    "data = []\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "for i in range(NODE_NUM):\n",
    "    if i in id2level:\n",
    "        new_item = level2speed[id2level[i]]\n",
    "    else:\n",
    "        new_item = 60\n",
    "    data.append(new_item)\n",
    "for key in data_dic:\n",
    "    id = name2id[key]\n",
    "    data[id] = data_dic[key]\n",
    "new = np.expand_dims(np.expand_dims(np.array(data),axis=0),axis=-1)\n",
    "res = np.concatenate([old, new], axis=2)\n",
    "for i in res[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac95797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}