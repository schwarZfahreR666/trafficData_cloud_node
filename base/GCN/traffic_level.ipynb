{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f819f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "from py2neo import Graph,Node,NodeMatcher\n",
    "import pandas as pd\n",
    "import dgl.function as fn\n",
    "import numpy as np\n",
    "from __future__ import division, print_function\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "import shelve\n",
    "from base.GCN.GraphSAGE import GCN,Classifier,Model\n",
    "from base.GCN.XGboost import XGBoost\n",
    "graph = Graph(\"http://47.95.159.86/:7474\",auth=(\"neo4j\",\"06240118\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8289ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取国家体育馆4跳之内的路名节点\n",
    "query = \"match (p:gym {name:'国家体育馆'})-[edge*1..4]->(q:road) return id(q) as qid,q.name as name;\"\n",
    "res = graph.run(query).data()\n",
    "nodesid = set()\n",
    "name2id = {}\n",
    "id2name = {}\n",
    "for row in res:\n",
    "    nodesid.add(row['qid'])\n",
    "    name2id[row['name']] = row['qid']\n",
    "    id2name[row['qid']] = row['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8997f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到各个路段\n",
    "query = \"match (p:road)-->(q:road) where id(q) in \" + str(list(nodesid)) + \" and id(p) in \" + str(list(nodesid)) + \" return id(p) as pid,id(q) as qid;\"\n",
    "res = graph.run(query).data()\n",
    "road_starts = []\n",
    "road_ends = []\n",
    "for row in res:\n",
    "    road_starts.append(row['pid'])\n",
    "    road_ends.append(row['qid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b8be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到与gym直接相连的路段\n",
    "query = \"match (p:gym)-->(q:road) where id(p)=0 return id(p) as pid,id(q) as qid;\"\n",
    "res = graph.run(query).data()\n",
    "gym_starts = []\n",
    "gym_ends = []\n",
    "for row in res:\n",
    "    gym_starts.append(row['pid'])\n",
    "    gym_ends.append(row['qid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e4810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到路段默认等级、限速\n",
    "level2speed = {\"1\":100,\"2\":100,\"3\":80,\"4\":80,\"5\":60,\"6\":60}\n",
    "query = \"match (p:road) where id(p) in \" + str(list(nodesid)) + \" return id(p) as pid,p.road_level as level;\"\n",
    "res = graph.run(query).data()\n",
    "id2level = {}\n",
    "for row in res:\n",
    "    id2level[row['pid']] = row['level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e600b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建gym和road两类节点的异质图\n",
    "graph_data = {\n",
    "   ('road', 'direct', 'gym'): (torch.tensor(gym_ends),torch.tensor(gym_starts)),\n",
    "   ('road', 'link', 'road'): (torch.tensor(road_starts), torch.tensor(road_ends))\n",
    "}\n",
    "g = dgl.heterograph(graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据组成\n",
    "data_file = \"./data.json\"\n",
    "data = []\n",
    "label = []\n",
    "with open(data_file,'r') as fd:\n",
    "        content = json.load(fd)\n",
    "        for item in content:\n",
    "            dic = {}\n",
    "            for key in item.keys():\n",
    "                if key in name2id:\n",
    "                    dic[name2id[key]] = item[key]\n",
    "                if key == 'label':\n",
    "                    label.append(item[key])\n",
    "            data.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f49301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按id顺序组装数据\n",
    "x_data = []  # data_num * node_num\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "ITEM_LEN = 6\n",
    "for item in data:\n",
    "    data_item = []\n",
    "    for i in range(NODE_NUM):\n",
    "        if i in item:\n",
    "            if i in id2level:\n",
    "                new_item = [x if x != -1 else level2speed[id2level[i]] for x in item[i]]\n",
    "            else:\n",
    "                new_item = [60 for x in item[i]]\n",
    "            data_item.append(new_item)\n",
    "        else:\n",
    "            if i in id2level:\n",
    "                default_item = [level2speed[id2level[i]] for _ in range(ITEM_LEN)]\n",
    "            else:\n",
    "                default_item = [60 for _ in range(ITEM_LEN)]\n",
    "            data_item.append(default_item)\n",
    "    x_data.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10508373",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.FloatTensor(x_data)\n",
    "_train_labels = [1,2,3]\n",
    "onehot_encoded = list()\n",
    "for value in label:\n",
    "    letter = [0 for _ in range(len(_train_labels))]\n",
    "    letter[value-1] = 1\n",
    "    onehot_encoded.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa6bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 220 462\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_data.shape[0]):\n",
    "    g.nodes['road'].data['speed'] = input_data[i]\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('speed', 'm'), fn.mean('m', 'h_1'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('h_1', 'm'), fn.mean('m', 'h_2'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['link'] = (fn.copy_u('h_2', 'm'), fn.mean('m', 'h_3'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    funcs = {}\n",
    "    funcs['direct'] = (fn.copy_u('h_3', 'f'), fn.mean('f', 'level'))\n",
    "    g.multi_update_all(funcs, 'sum')\n",
    "    level = torch.sum(g.nodes['gym'].data['level'] - 70)\n",
    "    traffic_level = 1\n",
    "    if float(level) < 13:\n",
    "        traffic_level = 2\n",
    "    if float(level) < 12:\n",
    "        traffic_level = 3\n",
    "    label[i] = traffic_level\n",
    "print(label.count(1),label.count(2),label.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbb915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for v in label:\n",
    "    item = []\n",
    "    item.append(v-1)\n",
    "    res.append(item)\n",
    "train_label = torch.LongTensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c6d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(12, 12)\n",
    "#         self.fc2 = nn.Linear(12, 6)\n",
    "#         self.sc1 = nn.Linear(12, 6)\n",
    "#         self.bn1 = nn.BatchNorm1d(12)\n",
    "#         self.ac1 = nn.LeakyReLU()\n",
    "\n",
    "#         self.fc3 = nn.Linear(12, 12)\n",
    "#         self.fc4 = nn.Linear(12, 6)\n",
    "#         self.sc2 = nn.Linear(12, 6)\n",
    "#         self.bn2 = nn.BatchNorm1d(12)\n",
    "#         self.ac2 = nn.LeakyReLU()\n",
    "        \n",
    "#         self.fc5 = nn.Linear(12, 12)\n",
    "#         self.fc6 = nn.Linear(12, 6)\n",
    "#         self.sc3 = nn.Linear(12, 6)\n",
    "#         self.bn3 = nn.BatchNorm1d(12)\n",
    "#         self.ac3 = nn.LeakyReLU()\n",
    "#     def forward(self, g, h):\n",
    "#         g.nodes['road'].data['speed'] = h\n",
    "        \n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('speed', 'm'), fn.mean('m', 'h_1'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h1_ = g.ndata['h_1']['road']\n",
    "        \n",
    "#         h1 = self.fc1(torch.cat([h, h1_], dim=1))\n",
    "#         x = h1\n",
    "#         h1 = self.bn1(h1)\n",
    "#         h1 = self.ac1(h1)\n",
    "#         h1 = self.fc2(h1) + self.sc1(x)\n",
    "        \n",
    "        \n",
    "#         g.nodes['road'].data['h_1'] = h1\n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('h_1', 'm'), fn.mean('m', 'h_2'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h2_ = g.ndata['h_2']['road']\n",
    "        \n",
    "#         h2 = self.fc3(torch.cat([h1, h2_], dim=1))\n",
    "#         x = h2\n",
    "#         h2 = self.bn2(h2)\n",
    "#         h2 = self.ac2(h2)\n",
    "#         h2 = self.fc4(h2) + self.sc2(x)\n",
    "        \n",
    "#         g.nodes['road'].data['h_2'] = h2\n",
    "#         funcs = {}\n",
    "#         funcs['link'] = (fn.copy_u('h_2', 'm'), fn.mean('m', 'h_3'))\n",
    "#         g.multi_update_all(funcs, 'mean')\n",
    "        \n",
    "#         h3_ = g.ndata['h_3']['road']\n",
    "        \n",
    "#         h3 = self.fc5(torch.cat([h2, h3_], dim=1))\n",
    "#         x = h3\n",
    "#         h3 = self.bn3(h3)\n",
    "#         h3 = self.ac3(h3)\n",
    "#         h3 = self.fc6(h3) + self.sc3(x)\n",
    "        \n",
    "#         g.nodes['road'].data['h_3'] = h3\n",
    "#         funcs = {}\n",
    "#         funcs['direct'] = (fn.copy_u('h_3', 'f'), fn.mean('f', 'level'))\n",
    "#         g.multi_update_all(funcs, 'sum')\n",
    "        \n",
    "#         return g.nodes['gym'].data['level']\n",
    "    \n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.classifier = nn.Linear(6, 3)\n",
    "#     def forward(self,h):\n",
    "#         res = self.classifier(h)\n",
    "#         return res\n",
    "    \n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self,gcn,classifier):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.gcn = gcn\n",
    "#         self.classifier = classifier\n",
    "#     def forward(self,g,h):\n",
    "#         res = self.classifier(self.gcn(g,h))\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01361c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,g, model,input_data,input_label):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "    p_num = 0\n",
    "    t_num = 0\n",
    "    pre_acc = 0\n",
    "    for ep in range(epoch):\n",
    "        for e in range(input_data.shape[0]):\n",
    "            # Forward\n",
    "            logits = model(g, input_data[e])\n",
    "\n",
    "            # Compute prediction\n",
    "            pred = logits.argmax(1)\n",
    "\n",
    "            # Compute loss\n",
    "            # Note that we should only compute the losses of the nodes in the training set,\n",
    "            # i.e. with train_mask 1.\n",
    "            loss = F.cross_entropy(logits, input_label[e])\n",
    "\n",
    "            # Compute accuracy on training/validation/test\n",
    "            train_acc = (pred == train_label[e]).float().mean()\n",
    "            p_num += (pred == train_label[e]).float()\n",
    "            t_num += 1\n",
    "\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc = float(p_num / t_num * 100)\n",
    "        print('acc: {:.3f}%'.format(acc))\n",
    "    torch.save(model.state_dict(), './model/GraphSAGE_pram.pkl')\n",
    "    print(\"better model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN()\n",
    "classifier = Classifier()\n",
    "model = Model(gcn,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd55a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 70.537%\n",
      "acc: 66.618%\n",
      "acc: 65.506%\n",
      "acc: 65.348%\n",
      "acc: 65.602%\n",
      "acc: 65.796%\n",
      "acc: 65.893%\n",
      "acc: 66.165%\n",
      "acc: 66.054%\n",
      "acc: 66.343%\n",
      "acc: 65.985%\n",
      "acc: 66.183%\n",
      "acc: 65.781%\n",
      "acc: 65.602%\n",
      "acc: 65.360%\n",
      "acc: 65.112%\n",
      "acc: 64.988%\n",
      "acc: 64.925%\n",
      "acc: 65.427%\n",
      "acc: 65.443%\n",
      "acc: 65.423%\n",
      "acc: 65.312%\n",
      "acc: 65.217%\n",
      "acc: 65.481%\n",
      "acc: 65.643%\n",
      "acc: 65.697%\n",
      "acc: 65.903%\n",
      "acc: 65.830%\n",
      "acc: 65.742%\n",
      "acc: 65.689%\n",
      "acc: 65.668%\n",
      "acc: 66.020%\n",
      "acc: 66.121%\n",
      "acc: 66.115%\n",
      "acc: 66.121%\n",
      "acc: 66.106%\n",
      "acc: 66.238%\n",
      "acc: 66.328%\n",
      "acc: 66.216%\n",
      "acc: 66.190%\n",
      "acc: 66.147%\n",
      "acc: 66.031%\n",
      "acc: 66.152%\n",
      "acc: 66.133%\n",
      "acc: 66.067%\n",
      "acc: 66.044%\n",
      "acc: 66.106%\n",
      "acc: 66.089%\n",
      "acc: 66.044%\n",
      "acc: 66.061%\n",
      "acc: 66.032%\n",
      "acc: 65.948%\n",
      "acc: 65.862%\n",
      "acc: 65.823%\n",
      "acc: 65.837%\n",
      "acc: 65.833%\n",
      "acc: 65.816%\n",
      "acc: 65.810%\n",
      "acc: 65.789%\n",
      "acc: 65.830%\n",
      "acc: 65.790%\n",
      "acc: 65.780%\n",
      "acc: 65.782%\n",
      "acc: 65.775%\n",
      "acc: 65.875%\n",
      "acc: 65.998%\n",
      "acc: 66.116%\n",
      "acc: 66.202%\n",
      "acc: 66.273%\n",
      "acc: 66.403%\n",
      "acc: 66.512%\n",
      "acc: 66.586%\n",
      "acc: 66.638%\n",
      "acc: 66.671%\n",
      "acc: 66.723%\n",
      "acc: 66.784%\n",
      "acc: 66.839%\n",
      "acc: 66.873%\n",
      "acc: 66.833%\n",
      "acc: 66.769%\n",
      "acc: 66.717%\n",
      "acc: 66.680%\n",
      "acc: 66.659%\n",
      "acc: 66.731%\n",
      "acc: 66.729%\n",
      "acc: 66.735%\n",
      "acc: 66.700%\n",
      "acc: 66.676%\n",
      "acc: 66.643%\n",
      "acc: 66.591%\n",
      "acc: 66.554%\n",
      "acc: 66.555%\n",
      "acc: 66.523%\n",
      "acc: 66.465%\n",
      "acc: 66.450%\n",
      "acc: 66.453%\n",
      "acc: 66.543%\n",
      "acc: 66.535%\n",
      "acc: 66.517%\n",
      "acc: 66.521%\n",
      "better model is saved\n"
     ]
    }
   ],
   "source": [
    "train(100,g,model,input_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae7bccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.850153120234609\n",
      "-5.806636300985701\n",
      "-5.8909469079226255\n",
      "-5.894065044820309\n",
      "-5.858153624460101\n",
      "-5.8266898933798075\n",
      "-5.90190333686769\n",
      "-5.854074273258448\n",
      "-5.901220019906759\n",
      "-5.914732380304486\n",
      "-5.894899714738131\n",
      "-5.854833452031016\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.9184138141572475\n",
      "-5.866314075887203\n",
      "-5.874931454658508\n",
      "-5.89053738117218\n",
      "-5.873285468667746\n",
      "-5.881950519979\n",
      "-5.864054799079895\n",
      "-5.94931236281991\n",
      "-5.8538230657577515\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.884188998490572\n",
      "-5.887137684971094\n",
      "-5.88066990673542\n",
      "-5.889011047780514\n",
      "-5.846630984917283\n",
      "-5.890574142336845\n",
      "-5.905116417212412\n",
      "-5.911250277014915\n",
      "-5.798846872523427\n",
      "-5.878703920170665\n",
      "-5.891047043725848\n",
      "-5.893193645402789\n",
      "-5.848597157746553\n",
      "-5.809330279007554\n",
      "-5.924394076690078\n",
      "-5.933820020407438\n",
      "-5.844829212874174\n",
      "-5.813285958021879\n",
      "-5.844420790672302\n",
      "-5.8980179047212005\n",
      "-5.8892829194664955\n",
      "-5.871151629835367\n",
      "-5.931992020457983\n",
      "-5.868022355251014\n",
      "-5.848496068269014\n",
      "-5.829644842073321\n",
      "-5.899266048334539\n",
      "-5.890304144471884\n",
      "-5.887650523334742\n",
      "-5.892920959740877\n",
      "-5.893609393388033\n",
      "-5.894479189068079\n",
      "-5.859395798295736\n",
      "-5.904164984822273\n",
      "-5.9149467293173075\n",
      "-5.894499409943819\n",
      "-5.854935310781002\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.855181518942118\n",
      "-5.832152355462313\n",
      "-5.89290064945817\n",
      "-5.861098073422909\n",
      "-5.938484475016594\n",
      "-5.886741443537176\n",
      "-5.8576844818890095\n",
      "-5.822419362142682\n",
      "-5.881168679799885\n",
      "-5.940869331359863\n",
      "-5.885856411419809\n",
      "-5.85481074731797\n",
      "-5.8302162773907185\n",
      "-5.898267149925232\n",
      "-5.888804718852043\n",
      "-5.883566554635763\n",
      "-5.897222116589546\n",
      "-5.894411768764257\n",
      "-5.888435862958431\n",
      "-5.879934333264828\n",
      "-5.885897811502218\n",
      "-5.8888850659132\n",
      "-5.892971254885197\n",
      "-5.896250043064356\n",
      "-5.891993630677462\n",
      "-5.888143602758646\n",
      "-5.883983787149191\n",
      "-5.889299001544714\n",
      "-5.8522180542349815\n",
      "-5.9369910061359406\n",
      "-5.889075106009841\n",
      "-5.866839408874512\n",
      "-5.797739094123244\n",
      "-5.924022035673261\n",
      "-5.948807369917631\n",
      "-5.845722945407033\n",
      "-5.831680601462722\n",
      "-5.901887221261859\n",
      "-5.9490768276154995\n",
      "-5.854576468467712\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.884338855743408\n",
      "-5.8852964751422405\n",
      "-5.8908726535737514\n",
      "-5.886339999735355\n",
      "-5.890202824026346\n",
      "-5.852017251774669\n",
      "-5.928856655955315\n",
      "-5.8822540156543255\n",
      "-5.866713631898165\n",
      "-5.8261682987213135\n",
      "-5.898176670074463\n",
      "-5.895227238535881\n",
      "-5.893917169421911\n",
      "-5.89503001049161\n",
      "-5.88419871032238\n",
      "-5.888031776994467\n",
      "-5.887510549277067\n",
      "-5.886407766491175\n",
      "-5.88593365997076\n",
      "-5.889513555914164\n",
      "-5.891202580183744\n",
      "-5.889371123164892\n",
      "-5.888398073613644\n",
      "-5.887269161641598\n",
      "-5.887374747544527\n",
      "-5.889850486069918\n",
      "-5.856508146971464\n",
      "-5.903017584234476\n",
      "-5.915338754653931\n",
      "-5.903094172477722\n",
      "-5.80244811065495\n",
      "-5.867659395560622\n",
      "-5.846838062629104\n",
      "-5.922167864628136\n",
      "-5.923375910148025\n",
      "-5.844376303255558\n",
      "-5.850462989415973\n",
      "-5.904269065707922\n",
      "-5.9469143487513065\n",
      "-5.86193323135376\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8573356326669455\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917111072689295\n",
      "-5.875788569450378\n",
      "-5.915069775655866\n",
      "-5.901727156713605\n",
      "-5.949245993047953\n",
      "-5.85403073951602\n",
      "-5.932369709014893\n",
      "-5.918178137391806\n",
      "-5.865019712597132\n",
      "-5.865450220182538\n",
      "-5.8472358314320445\n",
      "-5.893895528744906\n",
      "-5.888736724853516\n",
      "-5.892429556697607\n",
      "-5.8971432112157345\n",
      "-5.896878316998482\n",
      "-5.895639982074499\n",
      "-5.894821308553219\n",
      "-5.897554539144039\n",
      "-5.892549928277731\n",
      "-5.885062921792269\n",
      "-5.8844716884195805\n",
      "-5.885010037571192\n",
      "-5.854536945000291\n",
      "-5.9247109442949295\n",
      "-5.8801479446701705\n",
      "-5.845166011247784\n",
      "-5.8459133785218\n",
      "-5.78574282489717\n",
      "-5.647185981273651\n",
      "-5.919325619935989\n",
      "-4.626775115728378\n",
      "-5.884156867861748\n",
      "-5.891368627548218\n",
      "-5.892977345734835\n",
      "-5.857564903795719\n",
      "-5.900373566895723\n",
      "-5.942197950556874\n",
      "-5.855575907975435\n",
      "-5.79766575852409\n",
      "-5.889053290709853\n",
      "-5.900502996519208\n",
      "-5.86216451972723\n",
      "-5.819278120994568\n",
      "-5.899803334847093\n",
      "-5.891081377863884\n",
      "-5.8896607384085655\n",
      "-5.88679763302207\n",
      "-5.891583982855082\n",
      "-5.889891907572746\n",
      "-5.893187705427408\n",
      "-5.887095354497433\n",
      "-5.892105516046286\n",
      "-5.887329958379269\n",
      "-5.890388261526823\n",
      "-5.880646154284477\n",
      "-5.8794742822647095\n",
      "-5.877276744693518\n",
      "-5.849629836156964\n",
      "-5.930176876485348\n",
      "-5.885457375086844\n",
      "-5.8646725956350565\n",
      "-5.828288532793522\n",
      "-5.875438386690803\n",
      "-5.90741216018796\n",
      "-5.922288525849581\n",
      "-5.897424686700106\n",
      "-5.848453901708126\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.911428787279874\n",
      "-5.887523391284049\n",
      "-5.923004195094109\n",
      "-5.995016500353813\n",
      "-5.973630413413048\n",
      "-5.927531719207764\n",
      "-5.935912311077118\n",
      "-5.823162883520126\n",
      "-5.852252699434757\n",
      "-5.885549816302955\n",
      "-5.8596371952444315\n",
      "-5.793929837178439\n",
      "-5.911311528645456\n",
      "-5.932675903663039\n",
      "-5.85888671875\n",
      "-5.838325023651123\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917631682008505\n",
      "-5.878254111856222\n",
      "-5.915685566142201\n",
      "-5.900889169424772\n",
      "-5.888431213796139\n",
      "-5.800623698625714\n",
      "-5.882093147840351\n",
      "-5.939176797866821\n",
      "-5.894661632366478\n",
      "-5.85403073951602\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.802015759982169\n",
      "-5.84844459197484\n",
      "-5.897010293789208\n",
      "-5.893985226750374\n",
      "-5.876535013318062\n",
      "-5.87723708152771\n",
      "-5.847152482718229\n",
      "-5.90251325443387\n",
      "-5.912954698782414\n",
      "-5.897289947606623\n",
      "-5.850655447691679\n",
      "-5.859377145767212\n",
      "-5.863334493711591\n",
      "-5.845934683457017\n",
      "-5.901600285433233\n",
      "-5.859647069126368\n",
      "-5.903143581002951\n",
      "-5.9154990911483765\n",
      "-5.895471182651818\n",
      "-5.853799104690552\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.826274383813143\n",
      "-5.892030142247677\n",
      "-5.887242015451193\n",
      "-5.885483276098967\n",
      "-5.88181684166193\n",
      "-5.882712051272392\n",
      "-5.880945671349764\n",
      "-5.855271719396114\n",
      "-5.929169449955225\n",
      "-5.8731728359125555\n",
      "-5.862109649926424\n",
      "-5.828073197975755\n",
      "-5.898024819092825\n",
      "-5.869059637188911\n",
      "-5.8907182440161705\n",
      "-5.894781742244959\n",
      "-5.88186464458704\n",
      "-5.877543035894632\n",
      "-5.887318287044764\n",
      "-5.889762487262487\n",
      "-5.88740773499012\n",
      "-5.887234643101692\n",
      "-5.8861210979521275\n",
      "-5.884735964238644\n",
      "-5.885880719870329\n",
      "-5.887916304171085\n",
      "-5.851037545129657\n",
      "-5.898898135870695\n",
      "-5.943951345980167\n",
      "-5.858436563052237\n",
      "-5.801899064332247\n",
      "-5.832821423187852\n",
      "-5.9243737775832415\n",
      "-5.923060243949294\n",
      "-5.89468543138355\n",
      "-5.849951006472111\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917287230491638\n",
      "-5.87664058059454\n",
      "-5.9152807760983706\n",
      "-5.902055360376835\n",
      "-5.948899649083614\n",
      "-5.855140578001738\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8850659020245075\n",
      "-5.886783577501774\n",
      "-5.887892279773951\n",
      "-5.889437351375818\n",
      "-5.886363688856363\n",
      "-5.883270014077425\n",
      "-5.885542176663876\n",
      "-5.889149252325296\n",
      "-5.896419644355774\n",
      "-5.892816122621298\n",
      "-5.887140989303589\n",
      "-5.8914924412965775\n",
      "-5.883745312690735\n",
      "-5.88340749591589\n",
      "-5.8831206895411015\n",
      "-5.888705503195524\n",
      "-5.8910963088274\n",
      "-5.887699581682682\n",
      "-5.882519245147705\n",
      "-5.880298670381308\n",
      "-5.88464206084609\n",
      "-5.885661948472261\n",
      "-5.897204041481018\n",
      "-5.887727033346891\n",
      "-5.886363636702299\n",
      "-5.888447619974613\n",
      "-5.899830374866724\n",
      "-5.897536244243383\n",
      "-5.86334041133523\n",
      "-5.908001486212015\n",
      "-5.917583032511175\n",
      "-5.891880176030099\n",
      "-5.855314005166292\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8929513245821\n",
      "-5.903965149074793\n",
      "-5.896749172359705\n",
      "-5.88607919216156\n",
      "-5.884034298360348\n",
      "-5.89235308021307\n",
      "-5.895443417131901\n",
      "-5.855757657438517\n",
      "-5.904856625944376\n",
      "-5.9202282866463065\n",
      "-5.904772823676467\n",
      "-5.802783500403166\n",
      "-5.916385607793927\n",
      "-5.9039183631539345\n",
      "-5.947196200489998\n",
      "-5.860916614532471\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.91849098354578\n",
      "-5.866008594632149\n",
      "-5.863991379737854\n",
      "-5.839253794401884\n",
      "-5.936631862074137\n",
      "-5.858355869073421\n",
      "-5.881656624376774\n",
      "-5.86266835173592\n",
      "-5.944474784657359\n",
      "-5.8013523276895285\n",
      "-5.914875876158476\n",
      "-5.901425523683429\n",
      "-5.9495777525007725\n",
      "-5.852989055216312\n",
      "-5.932369709014893\n",
      "-5.91983588039875\n",
      "-5.887612048536539\n",
      "-5.918116612359881\n",
      "-5.907211933284998\n",
      "-5.944728538393974\n",
      "-5.870306070894003\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.842540567740798\n",
      "-5.8457548301666975\n",
      "-5.897502920590341\n",
      "-5.824042731896043\n",
      "-5.9017280880361795\n",
      "-5.884062897413969\n",
      "-5.87728613242507\n",
      "-5.886751674115658\n",
      "-5.8677573427557945\n",
      "-5.900689028203487\n",
      "-5.924058610573411\n",
      "-5.849904917180538\n",
      "-5.8097367393784225\n",
      "-5.88837224803865\n",
      "-5.900461424142122\n",
      "-5.862529905512929\n",
      "-5.805760838091373\n",
      "-5.934616673737764\n",
      "-5.864602229790762\n",
      "-5.856958367861807\n",
      "-5.824736010283232\n",
      "-5.900280085392296\n",
      "-5.887922201305628\n",
      "-5.892055805772543\n",
      "-5.897773839533329\n",
      "-5.857223402708769\n",
      "-5.935012824833393\n",
      "-5.878197745420039\n",
      "-5.872972076758742\n",
      "-5.798355503939092\n",
      "-5.941418766975403\n",
      "-5.870089509524405\n",
      "-5.874310276471078\n",
      "-5.825272483751178\n",
      "-5.878114136781733\n",
      "-5.930526465177536\n",
      "-5.859873804263771\n",
      "-5.880766110494733\n",
      "-5.862070072442293\n",
      "-5.9487737864255905\n",
      "-5.85146973375231\n",
      "-5.879550978541374\n",
      "-5.916019331663847\n",
      "-5.903277114033699\n",
      "-5.947741497308016\n",
      "-5.859007271006703\n",
      "-5.917288456112146\n",
      "-5.876645542681217\n",
      "-5.915280418470502\n",
      "-5.902057474479079\n",
      "-5.948897685855627\n",
      "-5.855147676542401\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.915839314460754\n",
      "-5.852812573313713\n",
      "-5.866498362272978\n",
      "-5.840286449936684\n",
      "-5.952110951766372\n",
      "-5.8830051105469465\n",
      "-5.834465135354549\n",
      "-5.848108010366559\n",
      "-5.939024535939097\n",
      "-5.89680814743042\n",
      "-5.8545844769105315\n",
      "-5.800031077116728\n",
      "-5.917219020426273\n",
      "-5.915547262411565\n",
      "-5.8948880871757865\n",
      "-5.854568589478731\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.916839338839054\n",
      "-5.874451365321875\n",
      "-5.914748765528202\n",
      "-5.900987538509071\n",
      "-5.890135373920202\n",
      "-5.808962713927031\n",
      "-5.844998944899999\n",
      "-5.898379954509437\n",
      "-5.882260322570801\n",
      "-5.891503777354956\n",
      "-5.857304908335209\n",
      "-5.902043212205172\n",
      "-5.916550322435796\n",
      "-5.895263628102839\n",
      "-5.850014340132475\n",
      "-5.877523995935917\n",
      "-5.915501929819584\n",
      "-5.902410896494985\n",
      "-5.948543690145016\n",
      "-5.856304384768009\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.823165730573237\n",
      "-5.86116461455822\n",
      "-5.910641886293888\n",
      "-5.822657477110624\n",
      "-5.886814787983894\n",
      "-5.889499068260193\n",
      "-5.877258125692606\n",
      "-5.881898544728756\n",
      "-5.894226506352425\n",
      "-5.885963201522827\n",
      "-5.874622453004122\n",
      "-5.87982814013958\n",
      "-5.894726697355509\n",
      "-5.894571792334318\n",
      "-5.89126405864954\n",
      "-5.8914987072348595\n",
      "-5.895056627690792\n",
      "-5.891806103289127\n",
      "-5.895716015249491\n",
      "-5.889324329793453\n",
      "-5.888346910476685\n",
      "-5.884471893310547\n",
      "-5.892397414892912\n",
      "-5.890350665897131\n",
      "-5.8893983997404575\n",
      "-5.884813264012337\n",
      "-5.885369334369898\n",
      "-5.88400361686945\n",
      "-5.884427763521671\n",
      "-5.849067764356732\n",
      "-5.933912746608257\n",
      "-5.884947896003723\n",
      "-5.844711130484939\n",
      "-5.84940735809505\n",
      "-5.943578936159611\n",
      "-5.894346757791936\n",
      "-5.849464058876038\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.888763830065727\n",
      "-5.880485609173775\n",
      "-5.885032512247562\n",
      "-5.8556291945278645\n",
      "-5.895347572863102\n",
      "-5.924615686759353\n",
      "-5.854959227144718\n",
      "-5.80846629338339\n",
      "-5.844387661432847\n",
      "-5.944086205214262\n",
      "-5.853457732591778\n",
      "-5.871301965788007\n",
      "-5.865808475762606\n",
      "-5.948908220976591\n",
      "-5.851118846796453\n",
      "-5.8653176464140415\n",
      "-5.876343065872788\n",
      "-5.885264277458191\n",
      "-5.93498907238245\n"
     ]
    }
   ],
   "source": [
    "mid_data = []\n",
    "for x in range(input_data.shape[0]):\n",
    "    logits = model(g, input_data[x])\n",
    "    pred = logits.argmax(1)\n",
    "#     print(pred,label[x])\n",
    "    level = gcn(g, input_data[x])\n",
    "    mid_data.append(level[0].tolist())\n",
    "for lis in mid_data:\n",
    "    print(sum(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d822ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.850153120234609\n",
      "-5.806636300985701\n",
      "-5.8909469079226255\n",
      "-5.894065044820309\n",
      "-5.858153624460101\n",
      "-5.8266898933798075\n",
      "-5.90190333686769\n",
      "-5.854074273258448\n",
      "-5.901220019906759\n",
      "-5.914732380304486\n",
      "-5.894899714738131\n",
      "-5.854833452031016\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.9184138141572475\n",
      "-5.866314075887203\n",
      "-5.874931454658508\n",
      "-5.89053738117218\n",
      "-5.873285468667746\n",
      "-5.881950519979\n",
      "-5.864054799079895\n",
      "-5.94931236281991\n",
      "-5.8538230657577515\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.884188998490572\n",
      "-5.887137684971094\n",
      "-5.88066990673542\n",
      "-5.889011047780514\n",
      "-5.846630984917283\n",
      "-5.890574142336845\n",
      "-5.905116417212412\n",
      "-5.911250277014915\n",
      "-5.798846872523427\n",
      "-5.878703920170665\n",
      "-5.891047043725848\n",
      "-5.893193645402789\n",
      "-5.848597157746553\n",
      "-5.809330279007554\n",
      "-5.924394076690078\n",
      "-5.933820020407438\n",
      "-5.844829212874174\n",
      "-5.813285958021879\n",
      "-5.844420790672302\n",
      "-5.8980179047212005\n",
      "-5.8892829194664955\n",
      "-5.871151629835367\n",
      "-5.931992020457983\n",
      "-5.868022355251014\n",
      "-5.848496068269014\n",
      "-5.829644842073321\n",
      "-5.899266048334539\n",
      "-5.890304144471884\n",
      "-5.887650523334742\n",
      "-5.892920959740877\n",
      "-5.893609393388033\n",
      "-5.894479189068079\n",
      "-5.859395798295736\n",
      "-5.904164984822273\n",
      "-5.9149467293173075\n",
      "-5.894499409943819\n",
      "-5.854935310781002\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.855181518942118\n",
      "-5.832152355462313\n",
      "-5.89290064945817\n",
      "-5.861098073422909\n",
      "-5.938484475016594\n",
      "-5.886741443537176\n",
      "-5.8576844818890095\n",
      "-5.822419362142682\n",
      "-5.881168679799885\n",
      "-5.940869331359863\n",
      "-5.885856411419809\n",
      "-5.85481074731797\n",
      "-5.8302162773907185\n",
      "-5.898267149925232\n",
      "-5.888804718852043\n",
      "-5.883566554635763\n",
      "-5.897222116589546\n",
      "-5.894411768764257\n",
      "-5.888435862958431\n",
      "-5.879934333264828\n",
      "-5.885897811502218\n",
      "-5.8888850659132\n",
      "-5.892971254885197\n",
      "-5.896250043064356\n",
      "-5.891993630677462\n",
      "-5.888143602758646\n",
      "-5.883983787149191\n",
      "-5.889299001544714\n",
      "-5.8522180542349815\n",
      "-5.9369910061359406\n",
      "-5.889075106009841\n",
      "-5.866839408874512\n",
      "-5.797739094123244\n",
      "-5.924022035673261\n",
      "-5.948807369917631\n",
      "-5.845722945407033\n",
      "-5.831680601462722\n",
      "-5.901887221261859\n",
      "-5.9490768276154995\n",
      "-5.854576468467712\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.884338855743408\n",
      "-5.8852964751422405\n",
      "-5.8908726535737514\n",
      "-5.886339999735355\n",
      "-5.890202824026346\n",
      "-5.852017251774669\n",
      "-5.928856655955315\n",
      "-5.8822540156543255\n",
      "-5.866713631898165\n",
      "-5.8261682987213135\n",
      "-5.898176670074463\n",
      "-5.895227238535881\n",
      "-5.893917169421911\n",
      "-5.89503001049161\n",
      "-5.88419871032238\n",
      "-5.888031776994467\n",
      "-5.887510549277067\n",
      "-5.886407766491175\n",
      "-5.88593365997076\n",
      "-5.889513555914164\n",
      "-5.891202580183744\n",
      "-5.889371123164892\n",
      "-5.888398073613644\n",
      "-5.887269161641598\n",
      "-5.887374747544527\n",
      "-5.889850486069918\n",
      "-5.856508146971464\n",
      "-5.903017584234476\n",
      "-5.915338754653931\n",
      "-5.903094172477722\n",
      "-5.80244811065495\n",
      "-5.867659395560622\n",
      "-5.846838062629104\n",
      "-5.922167864628136\n",
      "-5.923375910148025\n",
      "-5.844376303255558\n",
      "-5.850462989415973\n",
      "-5.904269065707922\n",
      "-5.9469143487513065\n",
      "-5.86193323135376\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8573356326669455\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917111072689295\n",
      "-5.875788569450378\n",
      "-5.915069775655866\n",
      "-5.901727156713605\n",
      "-5.949245993047953\n",
      "-5.85403073951602\n",
      "-5.932369709014893\n",
      "-5.918178137391806\n",
      "-5.865019712597132\n",
      "-5.865450220182538\n",
      "-5.8472358314320445\n",
      "-5.893895528744906\n",
      "-5.888736724853516\n",
      "-5.892429556697607\n",
      "-5.8971432112157345\n",
      "-5.896878316998482\n",
      "-5.895639982074499\n",
      "-5.894821308553219\n",
      "-5.897554539144039\n",
      "-5.892549928277731\n",
      "-5.885062921792269\n",
      "-5.8844716884195805\n",
      "-5.885010037571192\n",
      "-5.854536945000291\n",
      "-5.9247109442949295\n",
      "-5.8801479446701705\n",
      "-5.845166011247784\n",
      "-5.8459133785218\n",
      "-5.78574282489717\n",
      "-5.647185981273651\n",
      "-5.919325619935989\n",
      "-4.626775115728378\n",
      "-5.884156867861748\n",
      "-5.891368627548218\n",
      "-5.892977345734835\n",
      "-5.857564903795719\n",
      "-5.900373566895723\n",
      "-5.942197950556874\n",
      "-5.855575907975435\n",
      "-5.79766575852409\n",
      "-5.889053290709853\n",
      "-5.900502996519208\n",
      "-5.86216451972723\n",
      "-5.819278120994568\n",
      "-5.899803334847093\n",
      "-5.891081377863884\n",
      "-5.8896607384085655\n",
      "-5.88679763302207\n",
      "-5.891583982855082\n",
      "-5.889891907572746\n",
      "-5.893187705427408\n",
      "-5.887095354497433\n",
      "-5.892105516046286\n",
      "-5.887329958379269\n",
      "-5.890388261526823\n",
      "-5.880646154284477\n",
      "-5.8794742822647095\n",
      "-5.877276744693518\n",
      "-5.849629836156964\n",
      "-5.930176876485348\n",
      "-5.885457375086844\n",
      "-5.8646725956350565\n",
      "-5.828288532793522\n",
      "-5.875438386690803\n",
      "-5.90741216018796\n",
      "-5.922288525849581\n",
      "-5.897424686700106\n",
      "-5.848453901708126\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.911428787279874\n",
      "-5.887523391284049\n",
      "-5.923004195094109\n",
      "-5.995016500353813\n",
      "-5.973630413413048\n",
      "-5.927531719207764\n",
      "-5.935912311077118\n",
      "-5.823162883520126\n",
      "-5.852252699434757\n",
      "-5.885549816302955\n",
      "-5.8596371952444315\n",
      "-5.793929837178439\n",
      "-5.911311528645456\n",
      "-5.932675903663039\n",
      "-5.85888671875\n",
      "-5.838325023651123\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917631682008505\n",
      "-5.878254111856222\n",
      "-5.915685566142201\n",
      "-5.900889169424772\n",
      "-5.888431213796139\n",
      "-5.800623698625714\n",
      "-5.882093147840351\n",
      "-5.939176797866821\n",
      "-5.894661632366478\n",
      "-5.85403073951602\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.802015759982169\n",
      "-5.84844459197484\n",
      "-5.897010293789208\n",
      "-5.893985226750374\n",
      "-5.876535013318062\n",
      "-5.87723708152771\n",
      "-5.847152482718229\n",
      "-5.90251325443387\n",
      "-5.912954698782414\n",
      "-5.897289947606623\n",
      "-5.850655447691679\n",
      "-5.859377145767212\n",
      "-5.863334493711591\n",
      "-5.845934683457017\n",
      "-5.901600285433233\n",
      "-5.859647069126368\n",
      "-5.903143581002951\n",
      "-5.9154990911483765\n",
      "-5.895471182651818\n",
      "-5.853799104690552\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.826274383813143\n",
      "-5.892030142247677\n",
      "-5.887242015451193\n",
      "-5.885483276098967\n",
      "-5.88181684166193\n",
      "-5.882712051272392\n",
      "-5.880945671349764\n",
      "-5.855271719396114\n",
      "-5.929169449955225\n",
      "-5.8731728359125555\n",
      "-5.862109649926424\n",
      "-5.828073197975755\n",
      "-5.898024819092825\n",
      "-5.869059637188911\n",
      "-5.8907182440161705\n",
      "-5.894781742244959\n",
      "-5.88186464458704\n",
      "-5.877543035894632\n",
      "-5.887318287044764\n",
      "-5.889762487262487\n",
      "-5.88740773499012\n",
      "-5.887234643101692\n",
      "-5.8861210979521275\n",
      "-5.884735964238644\n",
      "-5.885880719870329\n",
      "-5.887916304171085\n",
      "-5.851037545129657\n",
      "-5.898898135870695\n",
      "-5.943951345980167\n",
      "-5.858436563052237\n",
      "-5.801899064332247\n",
      "-5.832821423187852\n",
      "-5.9243737775832415\n",
      "-5.923060243949294\n",
      "-5.89468543138355\n",
      "-5.849951006472111\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.917287230491638\n",
      "-5.87664058059454\n",
      "-5.9152807760983706\n",
      "-5.902055360376835\n",
      "-5.948899649083614\n",
      "-5.855140578001738\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8850659020245075\n",
      "-5.886783577501774\n",
      "-5.887892279773951\n",
      "-5.889437351375818\n",
      "-5.886363688856363\n",
      "-5.883270014077425\n",
      "-5.885542176663876\n",
      "-5.889149252325296\n",
      "-5.896419644355774\n",
      "-5.892816122621298\n",
      "-5.887140989303589\n",
      "-5.8914924412965775\n",
      "-5.883745312690735\n",
      "-5.88340749591589\n",
      "-5.8831206895411015\n",
      "-5.888705503195524\n",
      "-5.8910963088274\n",
      "-5.887699581682682\n",
      "-5.882519245147705\n",
      "-5.880298670381308\n",
      "-5.88464206084609\n",
      "-5.885661948472261\n",
      "-5.897204041481018\n",
      "-5.887727033346891\n",
      "-5.886363636702299\n",
      "-5.888447619974613\n",
      "-5.899830374866724\n",
      "-5.897536244243383\n",
      "-5.86334041133523\n",
      "-5.908001486212015\n",
      "-5.917583032511175\n",
      "-5.891880176030099\n",
      "-5.855314005166292\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.8929513245821\n",
      "-5.903965149074793\n",
      "-5.896749172359705\n",
      "-5.88607919216156\n",
      "-5.884034298360348\n",
      "-5.89235308021307\n",
      "-5.895443417131901\n",
      "-5.855757657438517\n",
      "-5.904856625944376\n",
      "-5.9202282866463065\n",
      "-5.904772823676467\n",
      "-5.802783500403166\n",
      "-5.916385607793927\n",
      "-5.9039183631539345\n",
      "-5.947196200489998\n",
      "-5.860916614532471\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.91849098354578\n",
      "-5.866008594632149\n",
      "-5.863991379737854\n",
      "-5.839253794401884\n",
      "-5.936631862074137\n",
      "-5.858355869073421\n",
      "-5.881656624376774\n",
      "-5.86266835173592\n",
      "-5.944474784657359\n",
      "-5.8013523276895285\n",
      "-5.914875876158476\n",
      "-5.901425523683429\n",
      "-5.9495777525007725\n",
      "-5.852989055216312\n",
      "-5.932369709014893\n",
      "-5.91983588039875\n",
      "-5.887612048536539\n",
      "-5.918116612359881\n",
      "-5.907211933284998\n",
      "-5.944728538393974\n",
      "-5.870306070894003\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.842540567740798\n",
      "-5.8457548301666975\n",
      "-5.897502920590341\n",
      "-5.824042731896043\n",
      "-5.9017280880361795\n",
      "-5.884062897413969\n",
      "-5.87728613242507\n",
      "-5.886751674115658\n",
      "-5.8677573427557945\n",
      "-5.900689028203487\n",
      "-5.924058610573411\n",
      "-5.849904917180538\n",
      "-5.8097367393784225\n",
      "-5.88837224803865\n",
      "-5.900461424142122\n",
      "-5.862529905512929\n",
      "-5.805760838091373\n",
      "-5.934616673737764\n",
      "-5.864602229790762\n",
      "-5.856958367861807\n",
      "-5.824736010283232\n",
      "-5.900280085392296\n",
      "-5.887922201305628\n",
      "-5.892055805772543\n",
      "-5.897773839533329\n",
      "-5.857223402708769\n",
      "-5.935012824833393\n",
      "-5.878197745420039\n",
      "-5.872972076758742\n",
      "-5.798355503939092\n",
      "-5.941418766975403\n",
      "-5.870089509524405\n",
      "-5.874310276471078\n",
      "-5.825272483751178\n",
      "-5.878114136781733\n",
      "-5.930526465177536\n",
      "-5.859873804263771\n",
      "-5.880766110494733\n",
      "-5.862070072442293\n",
      "-5.9487737864255905\n",
      "-5.85146973375231\n",
      "-5.879550978541374\n",
      "-5.916019331663847\n",
      "-5.903277114033699\n",
      "-5.947741497308016\n",
      "-5.859007271006703\n",
      "-5.917288456112146\n",
      "-5.876645542681217\n",
      "-5.915280418470502\n",
      "-5.902057474479079\n",
      "-5.948897685855627\n",
      "-5.855147676542401\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.915839314460754\n",
      "-5.852812573313713\n",
      "-5.866498362272978\n",
      "-5.840286449936684\n",
      "-5.952110951766372\n",
      "-5.8830051105469465\n",
      "-5.834465135354549\n",
      "-5.848108010366559\n",
      "-5.939024535939097\n",
      "-5.89680814743042\n",
      "-5.8545844769105315\n",
      "-5.800031077116728\n",
      "-5.917219020426273\n",
      "-5.915547262411565\n",
      "-5.8948880871757865\n",
      "-5.854568589478731\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.916839338839054\n",
      "-5.874451365321875\n",
      "-5.914748765528202\n",
      "-5.900987538509071\n",
      "-5.890135373920202\n",
      "-5.808962713927031\n",
      "-5.844998944899999\n",
      "-5.898379954509437\n",
      "-5.882260322570801\n",
      "-5.891503777354956\n",
      "-5.857304908335209\n",
      "-5.902043212205172\n",
      "-5.916550322435796\n",
      "-5.895263628102839\n",
      "-5.850014340132475\n",
      "-5.877523995935917\n",
      "-5.915501929819584\n",
      "-5.902410896494985\n",
      "-5.948543690145016\n",
      "-5.856304384768009\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.823165730573237\n",
      "-5.86116461455822\n",
      "-5.910641886293888\n",
      "-5.822657477110624\n",
      "-5.886814787983894\n",
      "-5.889499068260193\n",
      "-5.877258125692606\n",
      "-5.881898544728756\n",
      "-5.894226506352425\n",
      "-5.885963201522827\n",
      "-5.874622453004122\n",
      "-5.87982814013958\n",
      "-5.894726697355509\n",
      "-5.894571792334318\n",
      "-5.89126405864954\n",
      "-5.8914987072348595\n",
      "-5.895056627690792\n",
      "-5.891806103289127\n",
      "-5.895716015249491\n",
      "-5.889324329793453\n",
      "-5.888346910476685\n",
      "-5.884471893310547\n",
      "-5.892397414892912\n",
      "-5.890350665897131\n",
      "-5.8893983997404575\n",
      "-5.884813264012337\n",
      "-5.885369334369898\n",
      "-5.88400361686945\n",
      "-5.884427763521671\n",
      "-5.849067764356732\n",
      "-5.933912746608257\n",
      "-5.884947896003723\n",
      "-5.844711130484939\n",
      "-5.84940735809505\n",
      "-5.943578936159611\n",
      "-5.894346757791936\n",
      "-5.849464058876038\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.932369709014893\n",
      "-5.888763830065727\n",
      "-5.880485609173775\n",
      "-5.885032512247562\n",
      "-5.8556291945278645\n",
      "-5.895347572863102\n",
      "-5.924615686759353\n",
      "-5.854959227144718\n",
      "-5.80846629338339\n",
      "-5.844387661432847\n",
      "-5.944086205214262\n",
      "-5.853457732591778\n",
      "-5.871301965788007\n",
      "-5.865808475762606\n",
      "-5.948908220976591\n",
      "-5.851118846796453\n",
      "-5.8653176464140415\n",
      "-5.876343065872788\n",
      "-5.885264277458191\n",
      "-5.93498907238245\n"
     ]
    }
   ],
   "source": [
    "# load_model = torch.load(\"./model/GraphSAGE.pkl\")\n",
    "gcn = GCN()\n",
    "classifier = Classifier()\n",
    "load_model = Model(gcn,classifier)\n",
    "load_model.load_state_dict(torch.load(\"./model/GraphSAGE_pram.pkl\"))\n",
    "# load_model.eval()\n",
    "for x in range(input_data.shape[0]):\n",
    "    level = load_model.gcn(g, input_data[x])\n",
    "    print(sum(level[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a5d8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_widgets = [\n",
    "#     'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
    "#     ' ', progressbar.ETA()\n",
    "# ]\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n",
    "    mse = np.mean(np.power(y_true - y_pred, 2))\n",
    "    return mse\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    \n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    # Split the training data from test data in the ratio specified in\n",
    "    # test_size\n",
    "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "    X_train, X_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# def divide_on_feature(X, feature_i, threshold):\n",
    "#     \"\"\" Divide dataset based on if sample value on feature index is larger than\n",
    "#         the given threshold \"\"\"\n",
    "#     split_func = None\n",
    "#     if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "#         split_func = lambda sample: sample[feature_i] >= threshold\n",
    "#     else:\n",
    "#         split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "#     X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "#     X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
    "\n",
    "#     return np.array([X_1, X_2])\n",
    "\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]\n",
    "def pred2label(old):\n",
    "    new = []\n",
    "    for v in old:\n",
    "        new.append(round(v[0]))\n",
    "    return np.array(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3ca9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecisionNode():\n",
    "#     \"\"\"Class that represents a decision node or leaf in the decision tree\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     feature_i: int\n",
    "#         Feature index which we want to use as the threshold measure.\n",
    "#     threshold: float\n",
    "#         The value that we will compare feature values at feature_i against to\n",
    "#         determine the prediction.\n",
    "#     value: float\n",
    "#         The class prediction if classification tree, or float value if regression tree.\n",
    "#     true_branch: DecisionNode\n",
    "#         Next decision node for samples where features value met the threshold.\n",
    "#     false_branch: DecisionNode\n",
    "#         Next decision node for samples where features value did not meet the threshold.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, feature_i=None, threshold=None,\n",
    "#                  value=None, true_branch=None, false_branch=None):\n",
    "#         self.feature_i = feature_i  # Index for the feature that is tested\n",
    "#         self.threshold = threshold  # Threshold value for feature\n",
    "#         self.value = value  # Value if the node is a leaf in the tree\n",
    "#         self.true_branch = true_branch  # 'Left' subtree\n",
    "#         self.false_branch = false_branch  # 'Right' subtree\n",
    "        \n",
    "# class DecisionTree(object):\n",
    "#     \"\"\"Super class of RegressionTree and ClassificationTree.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     min_samples_split: int\n",
    "#         The minimum number of samples needed to make a split when building a tree.\n",
    "#     min_impurity: float\n",
    "#         The minimum impurity required to split the tree further.\n",
    "#     max_depth: int\n",
    "#         The maximum depth of a tree.\n",
    "#     loss: function\n",
    "#         Loss function that is used for Gradient Boosting models to calculate impurity.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, min_samples_split=2, min_impurity=1e-7,\n",
    "#                  max_depth=float(\"inf\"), loss=None):\n",
    "#         self.root = None  # Root node in dec. tree\n",
    "#         # Minimum n of samples to justify split\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#         # The minimum impurity to justify split\n",
    "#         self.min_impurity = min_impurity\n",
    "#         # The maximum depth to grow the tree to\n",
    "#         self.max_depth = max_depth\n",
    "#         # Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)\n",
    "#         # 切割树的方法，gini，方差等\n",
    "#         self._impurity_calculation = None\n",
    "#         # Function to determine prediction of y at leaf\n",
    "#         # 树节点取值的方法，分类树：选取出现最多次数的值，回归树：取所有值的平均值\n",
    "#         self._leaf_value_calculation = None\n",
    "#         # If y is one-hot encoded (multi-dim) or not (one-dim)\n",
    "#         self.one_dim = None\n",
    "#         # If Gradient Boost\n",
    "#         self.loss = loss\n",
    "\n",
    "#     def fit(self, X, y, loss=None):\n",
    "#         \"\"\" Build decision tree \"\"\"\n",
    "#         self.one_dim = len(np.shape(y)) == 1\n",
    "#         self.root = self._build_tree(X, y)\n",
    "#         self.loss = None\n",
    "\n",
    "#     def _build_tree(self, X, y, current_depth=0):\n",
    "#         \"\"\" Recursive method which builds out the decision tree and splits X and respective y\n",
    "#         on the feature of X which (based on impurity) best separates the data\"\"\"\n",
    "#         largest_impurity = 0\n",
    "#         best_criteria = None  # Feature index and threshold\n",
    "#         best_sets = None  # Subsets of the data\n",
    "\n",
    "#         # Check if expansion of y is needed  [1,2,3,4,5] -> [[1],[2],[3],[4],[5]]\n",
    "#         if len(np.shape(y)) == 1:\n",
    "#             y = np.expand_dims(y, axis=1)\n",
    "\n",
    "#         # Add y as last column of X\n",
    "#         Xy = np.concatenate((X, y), axis=1)\n",
    "\n",
    "#         n_samples, n_features = np.shape(X)\n",
    "#         # 节点样本数大于节点阈值并且没有达到最大树深\n",
    "#         if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "#             # Calculate the impurity for each feature\n",
    "#             for feature_i in range(n_features):\n",
    "#                 # All values of feature_i\n",
    "#                 feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "#                 unique_values = np.unique(feature_values)\n",
    "\n",
    "#                 # Iterate through all unique values of feature column i and\n",
    "#                 # calculate the impurity\n",
    "#                 for threshold in unique_values:\n",
    "#                     # Divide X and y depending on if the feature value of X at index feature_i\n",
    "#                     # meets the threshold\n",
    "#                     # 根据分割值分割样本\n",
    "#                     Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
    "\n",
    "#                     if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "#                         # Select the y-values of the two sets\n",
    "#                         # 拿到两部分的label\n",
    "#                         y1 = Xy1[:, n_features:]\n",
    "#                         y2 = Xy2[:, n_features:]\n",
    "\n",
    "#                         # Calculate impurity\n",
    "#                         impurity = self._impurity_calculation(y, y1, y2)\n",
    "\n",
    "#                         # If this threshold resulted in a higher information gain than previously\n",
    "#                         # recorded save the threshold value and the feature\n",
    "#                         # index\n",
    "#                         if impurity > largest_impurity:\n",
    "#                             largest_impurity = impurity\n",
    "#                             best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
    "#                             best_sets = {\n",
    "#                                 \"leftX\": Xy1[:, :n_features],  # X of left subtree\n",
    "#                                 \"lefty\": Xy1[:, n_features:],  # y of left subtree\n",
    "#                                 \"rightX\": Xy2[:, :n_features],  # X of right subtree\n",
    "#                                 \"righty\": Xy2[:, n_features:]  # y of right subtree\n",
    "#                             }\n",
    "\n",
    "#         if largest_impurity > self.min_impurity:\n",
    "#             # Build subtrees for the right and left branches\n",
    "#             true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
    "#             false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
    "#             return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\n",
    "#                 \"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "#         # We're at leaf => determine value\n",
    "#         leaf_value = self._leaf_value_calculation(y)\n",
    "#         return DecisionNode(value=leaf_value)\n",
    "\n",
    "#     def predict_value(self, x, tree=None):\n",
    "#         \"\"\" Do a recursive search down the tree and make a prediction of the data sample by the\n",
    "#             value of the leaf that we end up at \"\"\"\n",
    "\n",
    "#         if tree is None:\n",
    "#             tree = self.root\n",
    "\n",
    "#         # If we have a value (i.e we're at a leaf) => return value as the prediction\n",
    "#         if tree.value is not None:\n",
    "#             return tree.value\n",
    "\n",
    "#         # Choose the feature that we will test\n",
    "#         feature_value = x[tree.feature_i]\n",
    "\n",
    "#         # Determine if we will follow left or right branch\n",
    "#         branch = tree.false_branch\n",
    "#         if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "#             if feature_value >= tree.threshold:\n",
    "#                 branch = tree.true_branch\n",
    "#         elif feature_value == tree.threshold:\n",
    "#             branch = tree.true_branch\n",
    "\n",
    "#         # Test subtree\n",
    "#         return self.predict_value(x, branch)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\" Classify samples one by one and return the set of labels \"\"\"\n",
    "#         y_pred = []\n",
    "#         for x in X:\n",
    "#             y_pred.append(self.predict_value(x))\n",
    "#         return y_pred\n",
    "\n",
    "#     def print_tree(self, tree=None, indent=\" \"):\n",
    "#         \"\"\" Recursively print the decision tree \"\"\"\n",
    "#         if not tree:\n",
    "#             tree = self.root\n",
    "\n",
    "#         # If we're at leaf => print the label\n",
    "#         if tree.value is not None:\n",
    "#             print(tree.value)\n",
    "#         # Go deeper down the tree\n",
    "#         else:\n",
    "#             # Print test\n",
    "#             print(\"%s:%s? \" % (tree.feature_i, tree.threshold))\n",
    "#             # Print the true scenario\n",
    "#             print(\"%sT->\" % (indent), end=\"\")\n",
    "#             self.print_tree(tree.true_branch, indent + indent)\n",
    "#             # Print the false scenario\n",
    "#             print(\"%sF->\" % (indent), end=\"\")\n",
    "#             self.print_tree(tree.false_branch, indent + indent)\n",
    "\n",
    "# class LeastSquaresLoss():\n",
    "#     \"\"\"Least squares loss\"\"\"\n",
    "\n",
    "#     # g是loss一阶导\n",
    "#     def gradient(self, actual, predicted):\n",
    "#         return actual - predicted\n",
    "\n",
    "#     # h是loss二阶导\n",
    "#     def hess(self, actual, predicted):\n",
    "#         return np.ones_like(actual)\n",
    "\n",
    "# class XGBoostRegressionTree(DecisionTree):\n",
    "#     \"\"\"\n",
    "#     Regression tree for XGBoost\n",
    "#     - Reference -\n",
    "#     http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _split(self, y):\n",
    "#         \"\"\" y contains y_true in left half of the middle column and\n",
    "#         y_pred in the right half. Split and return the two matrices \"\"\"\n",
    "#         col = int(np.shape(y)[1]/2)\n",
    "#         y, y_pred = y[:, :col], y[:, col:]\n",
    "#         return y, y_pred\n",
    "\n",
    "#     def _gain(self, y, y_pred):\n",
    "#         nominator = np.power((self.loss.gradient(y, y_pred)).sum(), 2)\n",
    "#         denominator = self.loss.hess(y, y_pred).sum()\n",
    "#         return 0.5 * (nominator / denominator)\n",
    "\n",
    "#     def _gain_by_taylor(self, y, y1, y2):\n",
    "#         # Split\n",
    "#         y, y_pred = self._split(y)\n",
    "#         y1, y1_pred = self._split(y1)\n",
    "#         y2, y2_pred = self._split(y2)\n",
    "\n",
    "#         true_gain = self._gain(y1, y1_pred)\n",
    "#         false_gain = self._gain(y2, y2_pred)\n",
    "#         gain = self._gain(y, y_pred)\n",
    "#         return true_gain + false_gain - gain\n",
    "\n",
    "#     def _approximate_update(self, y):\n",
    "#         # y split into y, y_pred\n",
    "#         y, y_pred = self._split(y)\n",
    "#         gradient = np.sum(self.loss.gradient(y, y_pred),axis=0)\n",
    "#         hessian = np.sum(self.loss.hess(y, y_pred), axis=0)\n",
    "#         update_approximation =  gradient / hessian\n",
    "#         return update_approximation\n",
    "\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self._impurity_calculation = self._gain_by_taylor\n",
    "#         self._leaf_value_calculation = self._approximate_update\n",
    "#         super(XGBoostRegressionTree, self).fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class XGBoost(object):\n",
    "#     \"\"\"The XGBoost classifier.\n",
    "\n",
    "#     Reference: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     n_estimators: int\n",
    "#         The number of classification trees that are used.\n",
    "#     learning_rate: float\n",
    "#         The step length that will be taken when following the negative gradient during\n",
    "#         training.\n",
    "#     min_samples_split: int\n",
    "#         The minimum number of samples needed to make a split when building a tree.\n",
    "#     min_impurity: float\n",
    "#         The minimum impurity required to split the tree further.\n",
    "#     max_depth: int\n",
    "#         The maximum depth of a tree.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, n_estimators=200, learning_rate=0.01, min_samples_split=2,\n",
    "#                  min_impurity=1e-7, max_depth=2):\n",
    "#         self.n_estimators = n_estimators  # Number of trees\n",
    "#         self.learning_rate = learning_rate  # Step size for weight update\n",
    "#         self.min_samples_split = min_samples_split  # The minimum n of sampels to justify split\n",
    "#         self.min_impurity = min_impurity  # Minimum variance reduction to continue\n",
    "#         self.max_depth = max_depth  # Maximum depth for tree\n",
    "\n",
    "#         self.bar = progressbar.ProgressBar(widgets=bar_widgets)\n",
    "\n",
    "#         # Log loss for classification\n",
    "#         self.loss = LeastSquaresLoss()\n",
    "\n",
    "#         # Initialize regression trees\n",
    "#         self.trees = []\n",
    "#         for _ in range(n_estimators):\n",
    "#             tree = XGBoostRegressionTree(\n",
    "#                 min_samples_split=self.min_samples_split,\n",
    "#                 min_impurity=min_impurity,\n",
    "#                 max_depth=self.max_depth,\n",
    "#                 loss=self.loss)\n",
    "\n",
    "#             self.trees.append(tree)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         # y = to_categorical(y)\n",
    "#         m = X.shape[0]\n",
    "#         y = np.reshape(y, (m, -1))\n",
    "#         y_pred = np.zeros(np.shape(y))\n",
    "#         for i in self.bar(range(self.n_estimators)):\n",
    "#             tree = self.trees[i]\n",
    "#             y_and_pred = np.concatenate((y, y_pred), axis=1)\n",
    "#             tree.fit(X, y_and_pred)\n",
    "#             update_pred = tree.predict(X)\n",
    "#             update_pred = np.reshape(update_pred, (m, -1))\n",
    "#             y_pred += update_pred\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         y_pred = None\n",
    "#         m = X.shape[0]\n",
    "#         # Make predictions\n",
    "#         for tree in self.trees:\n",
    "#             # Estimate gradient and update prediction\n",
    "#             update_pred = tree.predict(X)\n",
    "#             update_pred = np.reshape(update_pred, (m, -1))\n",
    "#             if y_pred is None:\n",
    "#                 y_pred = np.zeros_like(update_pred)\n",
    "#             y_pred += update_pred\n",
    "\n",
    "#         return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b419f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print (\"-- XGBoost --\")\n",
    "    mid_data = np.array(mid_data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mid_data, label, test_size=0.5)\n",
    "    print(y_train)\n",
    "#     model = XGBoost()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     y_pred_line = model.predict(X)\n",
    "#     print(y_test[0:5])\n",
    "#     # Color map\n",
    "#     cmap = plt.get_cmap('viridis')\n",
    "\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "#     print (\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445c846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% [                                               ] ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- XGBoost --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangran/Desktop/traffic_platform/base/GCN/DecisionTree.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array([X_1, X_2])\n",
      "Training: 100% [------------------------------------------------] Time: 0:10:40\r\n"
     ]
    }
   ],
   "source": [
    "print (\"-- XGBoost --\")\n",
    "xg_data = np.array(mid_data)\n",
    "xg_label = np.array(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xg_data, xg_label, test_size=0.1)\n",
    "xg_model = XGBoost()\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bd34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error:0.490,acc:1.000\n",
      "Test Mean Squared Error:0.447,acc:0.941\n"
     ]
    }
   ],
   "source": [
    "y_tra = xg_model.predict(X_train)\n",
    "\n",
    "y_pred = xg_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_tra)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "acc_train = accuracy_score(y_train, pred2label(y_tra))\n",
    "acc_test = accuracy_score(y_test, pred2label(y_pred))\n",
    "\n",
    "\n",
    "print (\"Train Mean Squared Error:{:.3f},acc:{:.3f}\".format(float(mse_train),float(acc_train)))\n",
    "print (\"Test Mean Squared Error:{:.3f},acc:{:.3f}\".format(float(mse_test),float(acc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ed1de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 2 3 3 3 3 3 3 3 3 3 2 3 3 3 2 2 2 3 1 2 3 3 3 2 2 3 3 3 3 2 2 3 2 3\n",
      " 3 3 3 3 3 2 3 3 3 3 3 3 3 3 2 2 3 3 2 3 3 3 2 3 3 3 2 3 3 2 3]\n",
      "[3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg_model.predict(X_test)\n",
    "print(y_test)\n",
    "y_pd = []\n",
    "for v in y_pred:\n",
    "    y_pd.append(round(v[0]))\n",
    "print(y_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330bf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入\n",
    "def save(model):                      \n",
    "    db = shelve.open('./model/xg_boost')       # 创建二进制文件  赋值句柄给db\n",
    "    db['model'] = model         # 把实例化后的对象s赋值给db key为s\n",
    "    db.close()          # 保险起见  关闭一下文件 shelve自带的方法  .close()\n",
    "\n",
    "\n",
    "# 读取\n",
    "def read_shelve():\n",
    "    db = shelve.open('./model/xg_boost')           # 打开文件  赋值句柄给db\n",
    "    model = db['model']        # 把db['s']的值取出来给st\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97e4a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(xg_model.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.GCN.LevelAnalysisModel import ATAnalysisModel\n",
    "from base.GCN.XGBoostTree import XGBoostRegressionTree\n",
    "from base.GCN.DecisionTree import DecisionTree\n",
    "from base.GCN.DecisionNode import DecisionNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb1dae76",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'base/GCN/model/GraphSAGE_pram.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-5507c277661b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpredict_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mATAnalysisModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mpredict_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuildGraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mans\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/traffic_platform/base/GCN/LevelAnalysisModel.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mATAnalysisModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAnalysisModel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname2id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/traffic_platform/base/GCN/LevelAnalysisModel.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGraphSAGE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mGCN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGraphSAGE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMODEL_PATH\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/GraphSAGE_pram.pkl\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxg_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mXGBoost\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxg_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrees\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_shelve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/dgl/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 579\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    580\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    581\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/dgl/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/dgl/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'base/GCN/model/GraphSAGE_pram.pkl'"
     ]
    }
   ],
   "source": [
    "predict_model = ATAnalysisModel()\n",
    "predict_model.buildGraph(graph)\n",
    "ans = []\n",
    "for x in range(input_data.shape[0]):\n",
    "    res = predict_model.predict(input_data[x])\n",
    "    ans.append(res)\n",
    "xg_label = np.array(label)\n",
    "print(accuracy_score(np.array(label),np.array(ans)))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model.build_data()\n",
    "for item in predict_model.input_data[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {'京藏高速':22.1}\n",
    "predict_model.update_data(data_dic)\n",
    "for item in predict_model.input_data[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据组成\n",
    "data_file = \"./at_default_data.json\"\n",
    "data = []\n",
    "with open(data_file,'r') as fd:\n",
    "        content = json.load(fd)\n",
    "        dic = {}\n",
    "        for item in content:\n",
    "            \n",
    "            if item in name2id:\n",
    "                dic[name2id[item]] = content[item]\n",
    "        data.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按id顺序组装数据\n",
    "x_data = []  # data_num * node_num\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "ITEM_LEN = 6\n",
    "for item in data:\n",
    "    print(item)\n",
    "    data_item = []\n",
    "    for i in range(NODE_NUM):\n",
    "        if i in item:\n",
    "            if i in id2level:\n",
    "                new_item = [x if x != -1 else level2speed[id2level[i]] for x in item[i]]\n",
    "            else:\n",
    "                new_item = [60 for x in item[i]]\n",
    "            data_item.append(new_item)\n",
    "        else:\n",
    "            if i in id2level:\n",
    "                default_item = [level2speed[id2level[i]] for _ in range(ITEM_LEN)]\n",
    "            else:\n",
    "                default_item = [60 for _ in range(ITEM_LEN)]\n",
    "            data_item.append(default_item)\n",
    "    x_data.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e5308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.FloatTensor(x_data)\n",
    "data_np = input_data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eeb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1,2,3,4,5])\n",
    "num = -1\n",
    "fill_value = 0\n",
    "\n",
    "def shift(arr, num, fill_value):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:][:num] = fill_value\n",
    "        result[:][num:] = arr[:][:-num]\n",
    "    elif num < 0:\n",
    "        result[:][num:] = fill_value\n",
    "        result[:][:num] = arr[:][-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    print(result)\n",
    "shift(array, num, fill_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f249d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_np[:,:,1:data_np.shape[2]].shape)\n",
    "print(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {'京藏高速':22.1}\n",
    "np_array = input_data.numpy()\n",
    "old = np_array[:,:,:np_array.shape[2] - 1]\n",
    "data = []\n",
    "NODE_NUM = len(g.nodes('road'))\n",
    "for i in range(NODE_NUM):\n",
    "    if i in id2level:\n",
    "        new_item = level2speed[id2level[i]]\n",
    "    else:\n",
    "        new_item = 60\n",
    "    data.append(new_item)\n",
    "for key in data_dic:\n",
    "    id = name2id[key]\n",
    "    data[id] = data_dic[key]\n",
    "new = np.expand_dims(np.expand_dims(np.array(data),axis=0),axis=-1)\n",
    "res = np.concatenate([old, new], axis=2)\n",
    "for i in res[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac95797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}